I0321 20:45:15.305770  6540 caffe.cpp:186] Using GPUs 0
I0321 20:45:15.347007  6540 caffe.cpp:191] GPU 0: GeForce GTX 1080
I0321 20:45:15.578588  6540 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.0001
display: 100
max_iter: 30000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "/home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb"
solver_mode: GPU
device_id: 0
net: "/home/nikoong/Algorithm_test/handwritting/lenet/lenet_lmdb.prototxt"
I0321 20:45:15.578701  6540 solver.cpp:91] Creating training net from net file: /home/nikoong/Algorithm_test/handwritting/lenet/lenet_lmdb.prototxt
I0321 20:45:15.598009  6540 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0321 20:45:15.598037  6540 net.cpp:323] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0321 20:45:15.598134  6540 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/nikoong/Algorithm_test/handwritting/data/lmdb/finish/balance_train_lmdb"
    batch_size: 20000
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0321 20:45:15.598191  6540 layer_factory.hpp:77] Creating layer mnist
I0321 20:45:15.609982  6540 net.cpp:91] Creating Layer mnist
I0321 20:45:15.610015  6540 net.cpp:409] mnist -> data
I0321 20:45:15.610787  6547 db_lmdb.cpp:40] Opened lmdb /home/nikoong/Algorithm_test/handwritting/data/lmdb/finish/balance_train_lmdb
I0321 20:45:15.630136  6540 net.cpp:409] mnist -> label
I0321 20:45:18.433172  6540 data_layer.cpp:41] output data size: 20000,1,28,28
I0321 20:45:18.601624  6540 net.cpp:141] Setting up mnist
I0321 20:45:18.601670  6540 net.cpp:148] Top shape: 20000 1 28 28 (15680000)
I0321 20:45:18.601675  6540 net.cpp:148] Top shape: 20000 (20000)
I0321 20:45:18.601678  6540 net.cpp:156] Memory required for data: 62800000
I0321 20:45:18.601686  6540 layer_factory.hpp:77] Creating layer conv1
I0321 20:45:18.601737  6540 net.cpp:91] Creating Layer conv1
I0321 20:45:18.601766  6540 net.cpp:435] conv1 <- data
I0321 20:45:18.601791  6540 net.cpp:409] conv1 -> conv1
I0321 20:45:25.789203  6540 net.cpp:141] Setting up conv1
I0321 20:45:25.789227  6540 net.cpp:148] Top shape: 20000 20 24 24 (230400000)
I0321 20:45:25.789230  6540 net.cpp:156] Memory required for data: 984400000
I0321 20:45:25.789261  6540 layer_factory.hpp:77] Creating layer pool1
I0321 20:45:25.789274  6540 net.cpp:91] Creating Layer pool1
I0321 20:45:25.789280  6540 net.cpp:435] pool1 <- conv1
I0321 20:45:25.789285  6540 net.cpp:409] pool1 -> pool1
I0321 20:45:25.789337  6540 net.cpp:141] Setting up pool1
I0321 20:45:25.789343  6540 net.cpp:148] Top shape: 20000 20 12 12 (57600000)
I0321 20:45:25.789346  6540 net.cpp:156] Memory required for data: 1214800000
I0321 20:45:25.789348  6540 layer_factory.hpp:77] Creating layer conv2
I0321 20:45:25.789358  6540 net.cpp:91] Creating Layer conv2
I0321 20:45:25.789361  6540 net.cpp:435] conv2 <- pool1
I0321 20:45:25.789366  6540 net.cpp:409] conv2 -> conv2
I0321 20:45:25.791008  6540 net.cpp:141] Setting up conv2
I0321 20:45:25.791020  6540 net.cpp:148] Top shape: 20000 50 8 8 (64000000)
I0321 20:45:25.791023  6540 net.cpp:156] Memory required for data: 1470800000
I0321 20:45:25.791030  6540 layer_factory.hpp:77] Creating layer pool2
I0321 20:45:25.791036  6540 net.cpp:91] Creating Layer pool2
I0321 20:45:25.791038  6540 net.cpp:435] pool2 <- conv2
I0321 20:45:25.791054  6540 net.cpp:409] pool2 -> pool2
I0321 20:45:25.791082  6540 net.cpp:141] Setting up pool2
I0321 20:45:25.791096  6540 net.cpp:148] Top shape: 20000 50 4 4 (16000000)
I0321 20:45:25.791100  6540 net.cpp:156] Memory required for data: 1534800000
I0321 20:45:25.791101  6540 layer_factory.hpp:77] Creating layer ip1
I0321 20:45:25.791106  6540 net.cpp:91] Creating Layer ip1
I0321 20:45:25.791110  6540 net.cpp:435] ip1 <- pool2
I0321 20:45:25.791112  6540 net.cpp:409] ip1 -> ip1
I0321 20:45:25.794523  6540 net.cpp:141] Setting up ip1
I0321 20:45:25.794536  6540 net.cpp:148] Top shape: 20000 500 (10000000)
I0321 20:45:25.794539  6540 net.cpp:156] Memory required for data: 1574800000
I0321 20:45:25.794546  6540 layer_factory.hpp:77] Creating layer relu1
I0321 20:45:25.794553  6540 net.cpp:91] Creating Layer relu1
I0321 20:45:25.794555  6540 net.cpp:435] relu1 <- ip1
I0321 20:45:25.794559  6540 net.cpp:396] relu1 -> ip1 (in-place)
I0321 20:45:25.794705  6540 net.cpp:141] Setting up relu1
I0321 20:45:25.794713  6540 net.cpp:148] Top shape: 20000 500 (10000000)
I0321 20:45:25.794715  6540 net.cpp:156] Memory required for data: 1614800000
I0321 20:45:25.794718  6540 layer_factory.hpp:77] Creating layer ip2
I0321 20:45:25.794723  6540 net.cpp:91] Creating Layer ip2
I0321 20:45:25.794726  6540 net.cpp:435] ip2 <- ip1
I0321 20:45:25.794730  6540 net.cpp:409] ip2 -> ip2
I0321 20:45:25.795475  6540 net.cpp:141] Setting up ip2
I0321 20:45:25.795486  6540 net.cpp:148] Top shape: 20000 10 (200000)
I0321 20:45:25.795488  6540 net.cpp:156] Memory required for data: 1615600000
I0321 20:45:25.795495  6540 layer_factory.hpp:77] Creating layer loss
I0321 20:45:25.811110  6540 net.cpp:91] Creating Layer loss
I0321 20:45:25.811130  6540 net.cpp:435] loss <- ip2
I0321 20:45:25.811136  6540 net.cpp:435] loss <- label
I0321 20:45:25.811143  6540 net.cpp:409] loss -> loss
I0321 20:45:25.816298  6540 layer_factory.hpp:77] Creating layer loss
I0321 20:45:25.816751  6540 net.cpp:141] Setting up loss
I0321 20:45:25.816767  6540 net.cpp:148] Top shape: (1)
I0321 20:45:25.816771  6540 net.cpp:151]     with loss weight 1
I0321 20:45:25.816782  6540 net.cpp:156] Memory required for data: 1615600004
I0321 20:45:25.816787  6540 net.cpp:217] loss needs backward computation.
I0321 20:45:25.816789  6540 net.cpp:217] ip2 needs backward computation.
I0321 20:45:25.816792  6540 net.cpp:217] relu1 needs backward computation.
I0321 20:45:25.816795  6540 net.cpp:217] ip1 needs backward computation.
I0321 20:45:25.816798  6540 net.cpp:217] pool2 needs backward computation.
I0321 20:45:25.816802  6540 net.cpp:217] conv2 needs backward computation.
I0321 20:45:25.816805  6540 net.cpp:217] pool1 needs backward computation.
I0321 20:45:25.816808  6540 net.cpp:217] conv1 needs backward computation.
I0321 20:45:25.816812  6540 net.cpp:219] mnist does not need backward computation.
I0321 20:45:25.816814  6540 net.cpp:261] This network produces output loss
I0321 20:45:25.816835  6540 net.cpp:274] Network initialization done.
I0321 20:45:25.817088  6540 solver.cpp:181] Creating test net (#0) specified by net file: /home/nikoong/Algorithm_test/handwritting/lenet/lenet_lmdb.prototxt
I0321 20:45:25.817112  6540 net.cpp:323] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0321 20:45:25.817229  6540 net.cpp:49] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "/home/nikoong/Algorithm_test/handwritting/data/lmdb/finish/balance_val_lmdb"
    batch_size: 500
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0321 20:45:25.817276  6540 layer_factory.hpp:77] Creating layer mnist
I0321 20:45:25.817836  6540 net.cpp:91] Creating Layer mnist
I0321 20:45:25.817844  6540 net.cpp:409] mnist -> data
I0321 20:45:25.817852  6540 net.cpp:409] mnist -> label
I0321 20:45:25.818590  6549 db_lmdb.cpp:40] Opened lmdb /home/nikoong/Algorithm_test/handwritting/data/lmdb/finish/balance_val_lmdb
I0321 20:45:25.818702  6540 data_layer.cpp:41] output data size: 500,1,28,28
I0321 20:45:25.826392  6540 net.cpp:141] Setting up mnist
I0321 20:45:25.826412  6540 net.cpp:148] Top shape: 500 1 28 28 (392000)
I0321 20:45:25.826417  6540 net.cpp:148] Top shape: 500 (500)
I0321 20:45:25.826419  6540 net.cpp:156] Memory required for data: 1570000
I0321 20:45:25.826426  6540 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0321 20:45:25.826436  6540 net.cpp:91] Creating Layer label_mnist_1_split
I0321 20:45:25.826438  6540 net.cpp:435] label_mnist_1_split <- label
I0321 20:45:25.826444  6540 net.cpp:409] label_mnist_1_split -> label_mnist_1_split_0
I0321 20:45:25.826453  6540 net.cpp:409] label_mnist_1_split -> label_mnist_1_split_1
I0321 20:45:25.826504  6540 net.cpp:141] Setting up label_mnist_1_split
I0321 20:45:25.826510  6540 net.cpp:148] Top shape: 500 (500)
I0321 20:45:25.826514  6540 net.cpp:148] Top shape: 500 (500)
I0321 20:45:25.826516  6540 net.cpp:156] Memory required for data: 1574000
I0321 20:45:25.826519  6540 layer_factory.hpp:77] Creating layer conv1
I0321 20:45:25.826529  6540 net.cpp:91] Creating Layer conv1
I0321 20:45:25.826546  6540 net.cpp:435] conv1 <- data
I0321 20:45:25.826552  6540 net.cpp:409] conv1 -> conv1
I0321 20:45:25.828574  6540 net.cpp:141] Setting up conv1
I0321 20:45:25.828586  6540 net.cpp:148] Top shape: 500 20 24 24 (5760000)
I0321 20:45:25.828600  6540 net.cpp:156] Memory required for data: 24614000
I0321 20:45:25.828614  6540 layer_factory.hpp:77] Creating layer pool1
I0321 20:45:25.828627  6540 net.cpp:91] Creating Layer pool1
I0321 20:45:25.828632  6540 net.cpp:435] pool1 <- conv1
I0321 20:45:25.828637  6540 net.cpp:409] pool1 -> pool1
I0321 20:45:25.828670  6540 net.cpp:141] Setting up pool1
I0321 20:45:25.828675  6540 net.cpp:148] Top shape: 500 20 12 12 (1440000)
I0321 20:45:25.828678  6540 net.cpp:156] Memory required for data: 30374000
I0321 20:45:25.828680  6540 layer_factory.hpp:77] Creating layer conv2
I0321 20:45:25.828688  6540 net.cpp:91] Creating Layer conv2
I0321 20:45:25.828693  6540 net.cpp:435] conv2 <- pool1
I0321 20:45:25.828697  6540 net.cpp:409] conv2 -> conv2
I0321 20:45:25.829848  6540 net.cpp:141] Setting up conv2
I0321 20:45:25.829859  6540 net.cpp:148] Top shape: 500 50 8 8 (1600000)
I0321 20:45:25.829861  6540 net.cpp:156] Memory required for data: 36774000
I0321 20:45:25.829872  6540 layer_factory.hpp:77] Creating layer pool2
I0321 20:45:25.829881  6540 net.cpp:91] Creating Layer pool2
I0321 20:45:25.829885  6540 net.cpp:435] pool2 <- conv2
I0321 20:45:25.829888  6540 net.cpp:409] pool2 -> pool2
I0321 20:45:25.829917  6540 net.cpp:141] Setting up pool2
I0321 20:45:25.829923  6540 net.cpp:148] Top shape: 500 50 4 4 (400000)
I0321 20:45:25.829926  6540 net.cpp:156] Memory required for data: 38374000
I0321 20:45:25.829931  6540 layer_factory.hpp:77] Creating layer ip1
I0321 20:45:25.829936  6540 net.cpp:91] Creating Layer ip1
I0321 20:45:25.829941  6540 net.cpp:435] ip1 <- pool2
I0321 20:45:25.829952  6540 net.cpp:409] ip1 -> ip1
I0321 20:45:25.833426  6540 net.cpp:141] Setting up ip1
I0321 20:45:25.833453  6540 net.cpp:148] Top shape: 500 500 (250000)
I0321 20:45:25.833457  6540 net.cpp:156] Memory required for data: 39374000
I0321 20:45:25.833467  6540 layer_factory.hpp:77] Creating layer relu1
I0321 20:45:25.833475  6540 net.cpp:91] Creating Layer relu1
I0321 20:45:25.833479  6540 net.cpp:435] relu1 <- ip1
I0321 20:45:25.833483  6540 net.cpp:396] relu1 -> ip1 (in-place)
I0321 20:45:25.834089  6540 net.cpp:141] Setting up relu1
I0321 20:45:25.834101  6540 net.cpp:148] Top shape: 500 500 (250000)
I0321 20:45:25.834106  6540 net.cpp:156] Memory required for data: 40374000
I0321 20:45:25.834110  6540 layer_factory.hpp:77] Creating layer ip2
I0321 20:45:25.834118  6540 net.cpp:91] Creating Layer ip2
I0321 20:45:25.834121  6540 net.cpp:435] ip2 <- ip1
I0321 20:45:25.834128  6540 net.cpp:409] ip2 -> ip2
I0321 20:45:25.834270  6540 net.cpp:141] Setting up ip2
I0321 20:45:25.834277  6540 net.cpp:148] Top shape: 500 10 (5000)
I0321 20:45:25.834364  6540 net.cpp:156] Memory required for data: 40394000
I0321 20:45:25.834388  6540 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0321 20:45:25.834398  6540 net.cpp:91] Creating Layer ip2_ip2_0_split
I0321 20:45:25.834401  6540 net.cpp:435] ip2_ip2_0_split <- ip2
I0321 20:45:25.834408  6540 net.cpp:409] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0321 20:45:25.834419  6540 net.cpp:409] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0321 20:45:25.834451  6540 net.cpp:141] Setting up ip2_ip2_0_split
I0321 20:45:25.834457  6540 net.cpp:148] Top shape: 500 10 (5000)
I0321 20:45:25.834462  6540 net.cpp:148] Top shape: 500 10 (5000)
I0321 20:45:25.834465  6540 net.cpp:156] Memory required for data: 40434000
I0321 20:45:25.834470  6540 layer_factory.hpp:77] Creating layer accuracy
I0321 20:45:25.834481  6540 net.cpp:91] Creating Layer accuracy
I0321 20:45:25.834484  6540 net.cpp:435] accuracy <- ip2_ip2_0_split_0
I0321 20:45:25.834491  6540 net.cpp:435] accuracy <- label_mnist_1_split_0
I0321 20:45:25.834496  6540 net.cpp:409] accuracy -> accuracy
I0321 20:45:25.834502  6540 net.cpp:141] Setting up accuracy
I0321 20:45:25.834506  6540 net.cpp:148] Top shape: (1)
I0321 20:45:25.834520  6540 net.cpp:156] Memory required for data: 40434004
I0321 20:45:25.834522  6540 layer_factory.hpp:77] Creating layer loss
I0321 20:45:25.834530  6540 net.cpp:91] Creating Layer loss
I0321 20:45:25.834537  6540 net.cpp:435] loss <- ip2_ip2_0_split_1
I0321 20:45:25.834540  6540 net.cpp:435] loss <- label_mnist_1_split_1
I0321 20:45:25.834545  6540 net.cpp:409] loss -> loss
I0321 20:45:25.834553  6540 layer_factory.hpp:77] Creating layer loss
I0321 20:45:25.834745  6540 net.cpp:141] Setting up loss
I0321 20:45:25.834754  6540 net.cpp:148] Top shape: (1)
I0321 20:45:25.834771  6540 net.cpp:151]     with loss weight 1
I0321 20:45:25.834781  6540 net.cpp:156] Memory required for data: 40434008
I0321 20:45:25.834784  6540 net.cpp:217] loss needs backward computation.
I0321 20:45:25.834789  6540 net.cpp:219] accuracy does not need backward computation.
I0321 20:45:25.834792  6540 net.cpp:217] ip2_ip2_0_split needs backward computation.
I0321 20:45:25.834794  6540 net.cpp:217] ip2 needs backward computation.
I0321 20:45:25.834799  6540 net.cpp:217] relu1 needs backward computation.
I0321 20:45:25.834800  6540 net.cpp:217] ip1 needs backward computation.
I0321 20:45:25.834807  6540 net.cpp:217] pool2 needs backward computation.
I0321 20:45:25.834810  6540 net.cpp:217] conv2 needs backward computation.
I0321 20:45:25.834815  6540 net.cpp:217] pool1 needs backward computation.
I0321 20:45:25.834817  6540 net.cpp:217] conv1 needs backward computation.
I0321 20:45:25.834822  6540 net.cpp:219] label_mnist_1_split does not need backward computation.
I0321 20:45:25.834825  6540 net.cpp:219] mnist does not need backward computation.
I0321 20:45:25.834828  6540 net.cpp:261] This network produces output accuracy
I0321 20:45:25.834833  6540 net.cpp:261] This network produces output loss
I0321 20:45:25.834844  6540 net.cpp:274] Network initialization done.
I0321 20:45:25.834899  6540 solver.cpp:60] Solver scaffolding done.
I0321 20:45:25.835131  6540 caffe.cpp:129] Finetuning from /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/history_snap/mnist_10000.caffemodel
I0321 20:45:25.856158  6540 net.cpp:765] Copying source layer mnist
I0321 20:45:25.856176  6540 net.cpp:765] Copying source layer conv1
I0321 20:45:25.856185  6540 net.cpp:765] Copying source layer pool1
I0321 20:45:25.856189  6540 net.cpp:765] Copying source layer conv2
I0321 20:45:25.856209  6540 net.cpp:765] Copying source layer pool2
I0321 20:45:25.856211  6540 net.cpp:765] Copying source layer ip1
I0321 20:45:25.856444  6540 net.cpp:765] Copying source layer relu1
I0321 20:45:25.856451  6540 net.cpp:765] Copying source layer ip2
I0321 20:45:25.856457  6540 net.cpp:765] Copying source layer loss
I0321 20:45:25.856950  6540 net.cpp:765] Copying source layer mnist
I0321 20:45:25.856957  6540 net.cpp:765] Copying source layer conv1
I0321 20:45:25.856961  6540 net.cpp:765] Copying source layer pool1
I0321 20:45:25.856963  6540 net.cpp:765] Copying source layer conv2
I0321 20:45:25.856979  6540 net.cpp:765] Copying source layer pool2
I0321 20:45:25.856982  6540 net.cpp:765] Copying source layer ip1
I0321 20:45:25.857169  6540 net.cpp:765] Copying source layer relu1
I0321 20:45:25.857174  6540 net.cpp:765] Copying source layer ip2
I0321 20:45:25.857180  6540 net.cpp:765] Copying source layer loss
I0321 20:45:25.857195  6540 caffe.cpp:220] Starting Optimization
I0321 20:45:25.857203  6540 solver.cpp:279] Solving LeNet
I0321 20:45:25.857205  6540 solver.cpp:280] Learning Rate Policy: inv
I0321 20:45:25.857933  6540 solver.cpp:337] Iteration 0, Testing net (#0)
I0321 20:45:26.341086  6540 solver.cpp:404]     Test net output #0: accuracy = 0.62698
I0321 20:45:26.341122  6540 solver.cpp:404]     Test net output #1: loss = 1.52971 (* 1 = 1.52971 loss)
I0321 20:45:26.494906  6540 solver.cpp:228] Iteration 0, loss = 1.55618
I0321 20:45:26.494941  6540 solver.cpp:244]     Train net output #0: loss = 1.55618 (* 1 = 1.55618 loss)
I0321 20:45:26.494952  6540 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0321 20:45:57.634940  6540 solver.cpp:228] Iteration 100, loss = 1.12757
I0321 20:45:57.635043  6540 solver.cpp:244]     Train net output #0: loss = 1.12757 (* 1 = 1.12757 loss)
I0321 20:45:57.635052  6540 sgd_solver.cpp:106] Iteration 100, lr = 9.92565e-05
I0321 20:46:29.326848  6540 solver.cpp:228] Iteration 200, loss = 1.00795
I0321 20:46:29.326923  6540 solver.cpp:244]     Train net output #0: loss = 1.00795 (* 1 = 1.00795 loss)
I0321 20:46:29.326932  6540 sgd_solver.cpp:106] Iteration 200, lr = 9.85258e-05
I0321 20:47:00.840185  6540 solver.cpp:228] Iteration 300, loss = 0.905997
I0321 20:47:00.840256  6540 solver.cpp:244]     Train net output #0: loss = 0.905997 (* 1 = 0.905997 loss)
I0321 20:47:00.840265  6540 sgd_solver.cpp:106] Iteration 300, lr = 9.78075e-05
I0321 20:47:32.452386  6540 solver.cpp:228] Iteration 400, loss = 0.873383
I0321 20:47:32.452455  6540 solver.cpp:244]     Train net output #0: loss = 0.873383 (* 1 = 0.873383 loss)
I0321 20:47:32.452463  6540 sgd_solver.cpp:106] Iteration 400, lr = 9.71013e-05
I0321 20:48:04.075353  6540 solver.cpp:337] Iteration 500, Testing net (#0)
I0321 20:48:04.749817  6540 solver.cpp:404]     Test net output #0: accuracy = 0.75258
I0321 20:48:04.749856  6540 solver.cpp:404]     Test net output #1: loss = 0.844301 (* 1 = 0.844301 loss)
I0321 20:48:04.883862  6540 solver.cpp:228] Iteration 500, loss = 0.848866
I0321 20:48:04.883898  6540 solver.cpp:244]     Train net output #0: loss = 0.848866 (* 1 = 0.848866 loss)
I0321 20:48:04.883905  6540 sgd_solver.cpp:106] Iteration 500, lr = 9.64069e-05
I0321 20:48:36.923300  6540 solver.cpp:228] Iteration 600, loss = 0.809313
I0321 20:48:36.923359  6540 solver.cpp:244]     Train net output #0: loss = 0.809313 (* 1 = 0.809313 loss)
I0321 20:48:36.923375  6540 sgd_solver.cpp:106] Iteration 600, lr = 9.57239e-05
I0321 20:49:12.782657  6540 solver.cpp:228] Iteration 700, loss = 0.755984
I0321 20:49:12.782740  6540 solver.cpp:244]     Train net output #0: loss = 0.755984 (* 1 = 0.755984 loss)
I0321 20:49:12.782757  6540 sgd_solver.cpp:106] Iteration 700, lr = 9.50522e-05
I0321 20:49:44.779714  6540 solver.cpp:228] Iteration 800, loss = 0.746211
I0321 20:49:44.779813  6540 solver.cpp:244]     Train net output #0: loss = 0.746211 (* 1 = 0.746211 loss)
I0321 20:49:44.779820  6540 sgd_solver.cpp:106] Iteration 800, lr = 9.43913e-05
I0321 20:50:16.835644  6540 solver.cpp:228] Iteration 900, loss = 0.743482
I0321 20:50:16.835741  6540 solver.cpp:244]     Train net output #0: loss = 0.743482 (* 1 = 0.743482 loss)
I0321 20:50:16.835749  6540 sgd_solver.cpp:106] Iteration 900, lr = 9.37411e-05
I0321 20:50:48.767015  6540 solver.cpp:337] Iteration 1000, Testing net (#0)
I0321 20:50:49.441134  6540 solver.cpp:404]     Test net output #0: accuracy = 0.78166
I0321 20:50:49.441171  6540 solver.cpp:404]     Test net output #1: loss = 0.725454 (* 1 = 0.725454 loss)
I0321 20:50:49.577675  6540 solver.cpp:228] Iteration 1000, loss = 0.722223
I0321 20:50:49.577713  6540 solver.cpp:244]     Train net output #0: loss = 0.722223 (* 1 = 0.722223 loss)
I0321 20:50:49.577721  6540 sgd_solver.cpp:106] Iteration 1000, lr = 9.31012e-05
I0321 20:51:21.744225  6540 solver.cpp:228] Iteration 1100, loss = 0.687391
I0321 20:51:21.744293  6540 solver.cpp:244]     Train net output #0: loss = 0.687391 (* 1 = 0.687391 loss)
I0321 20:51:21.744302  6540 sgd_solver.cpp:106] Iteration 1100, lr = 9.24715e-05
I0321 20:51:53.967923  6540 solver.cpp:228] Iteration 1200, loss = 0.679118
I0321 20:51:53.968027  6540 solver.cpp:244]     Train net output #0: loss = 0.679118 (* 1 = 0.679118 loss)
I0321 20:51:53.968035  6540 sgd_solver.cpp:106] Iteration 1200, lr = 9.18515e-05
I0321 20:52:26.123509  6540 solver.cpp:228] Iteration 1300, loss = 0.683096
I0321 20:52:26.123608  6540 solver.cpp:244]     Train net output #0: loss = 0.683096 (* 1 = 0.683096 loss)
I0321 20:52:26.123625  6540 sgd_solver.cpp:106] Iteration 1300, lr = 9.12412e-05
I0321 20:52:58.662189  6540 solver.cpp:228] Iteration 1400, loss = 0.670947
I0321 20:52:58.662312  6540 solver.cpp:244]     Train net output #0: loss = 0.670947 (* 1 = 0.670947 loss)
I0321 20:52:58.662322  6540 sgd_solver.cpp:106] Iteration 1400, lr = 9.06403e-05
I0321 20:53:31.099740  6540 solver.cpp:337] Iteration 1500, Testing net (#0)
I0321 20:53:31.318033  6540 blocking_queue.cpp:50] Data layer prefetch queue empty
I0321 20:53:31.807304  6540 solver.cpp:404]     Test net output #0: accuracy = 0.79782
I0321 20:53:31.807335  6540 solver.cpp:404]     Test net output #1: loss = 0.663751 (* 1 = 0.663751 loss)
I0321 20:53:31.939079  6540 solver.cpp:228] Iteration 1500, loss = 0.641241
I0321 20:53:31.939103  6540 solver.cpp:244]     Train net output #0: loss = 0.641241 (* 1 = 0.641241 loss)
I0321 20:53:31.939110  6540 sgd_solver.cpp:106] Iteration 1500, lr = 9.00485e-05
I0321 20:54:04.119510  6540 solver.cpp:228] Iteration 1600, loss = 0.640476
I0321 20:54:04.119596  6540 solver.cpp:244]     Train net output #0: loss = 0.640476 (* 1 = 0.640476 loss)
I0321 20:54:04.119612  6540 sgd_solver.cpp:106] Iteration 1600, lr = 8.94657e-05
I0321 20:54:37.210615  6540 solver.cpp:228] Iteration 1700, loss = 0.641465
I0321 20:54:37.210721  6540 solver.cpp:244]     Train net output #0: loss = 0.641465 (* 1 = 0.641465 loss)
I0321 20:54:37.210729  6540 sgd_solver.cpp:106] Iteration 1700, lr = 8.88916e-05
I0321 20:55:09.609576  6540 solver.cpp:228] Iteration 1800, loss = 0.635287
I0321 20:55:09.609678  6540 solver.cpp:244]     Train net output #0: loss = 0.635287 (* 1 = 0.635287 loss)
I0321 20:55:09.609686  6540 sgd_solver.cpp:106] Iteration 1800, lr = 8.8326e-05
I0321 20:55:41.660253  6540 solver.cpp:228] Iteration 1900, loss = 0.606525
I0321 20:55:41.660804  6540 solver.cpp:244]     Train net output #0: loss = 0.606525 (* 1 = 0.606525 loss)
I0321 20:55:41.660811  6540 sgd_solver.cpp:106] Iteration 1900, lr = 8.77687e-05
I0321 20:56:14.443735  6540 solver.cpp:337] Iteration 2000, Testing net (#0)
I0321 20:56:15.100047  6540 solver.cpp:404]     Test net output #0: accuracy = 0.80914
I0321 20:56:15.100076  6540 solver.cpp:404]     Test net output #1: loss = 0.62419 (* 1 = 0.62419 loss)
I0321 20:56:15.232677  6540 solver.cpp:228] Iteration 2000, loss = 0.610622
I0321 20:56:15.232738  6540 solver.cpp:244]     Train net output #0: loss = 0.610622 (* 1 = 0.610622 loss)
I0321 20:56:15.232755  6540 sgd_solver.cpp:106] Iteration 2000, lr = 8.72196e-05
I0321 20:56:50.112839  6540 solver.cpp:228] Iteration 2100, loss = 0.614599
I0321 20:56:50.112908  6540 solver.cpp:244]     Train net output #0: loss = 0.614599 (* 1 = 0.614599 loss)
I0321 20:56:50.112916  6540 sgd_solver.cpp:106] Iteration 2100, lr = 8.66784e-05
I0321 20:57:22.730187  6540 solver.cpp:228] Iteration 2200, loss = 0.607088
I0321 20:57:22.730259  6540 solver.cpp:244]     Train net output #0: loss = 0.607088 (* 1 = 0.607088 loss)
I0321 20:57:22.730268  6540 sgd_solver.cpp:106] Iteration 2200, lr = 8.6145e-05
I0321 20:57:55.622573  6540 solver.cpp:228] Iteration 2300, loss = 0.580703
I0321 20:57:55.622669  6540 solver.cpp:244]     Train net output #0: loss = 0.580703 (* 1 = 0.580703 loss)
I0321 20:57:55.622678  6540 sgd_solver.cpp:106] Iteration 2300, lr = 8.56192e-05
I0321 20:58:28.291388  6540 solver.cpp:228] Iteration 2400, loss = 0.586254
I0321 20:58:28.291450  6540 solver.cpp:244]     Train net output #0: loss = 0.586254 (* 1 = 0.586254 loss)
I0321 20:58:28.291460  6540 sgd_solver.cpp:106] Iteration 2400, lr = 8.51008e-05
I0321 20:59:03.089756  6540 solver.cpp:337] Iteration 2500, Testing net (#0)
I0321 20:59:03.796640  6540 solver.cpp:404]     Test net output #0: accuracy = 0.81748
I0321 20:59:03.796679  6540 solver.cpp:404]     Test net output #1: loss = 0.596456 (* 1 = 0.596456 loss)
I0321 20:59:03.929829  6540 solver.cpp:228] Iteration 2500, loss = 0.591603
I0321 20:59:03.929895  6540 solver.cpp:244]     Train net output #0: loss = 0.591603 (* 1 = 0.591603 loss)
I0321 20:59:03.929920  6540 sgd_solver.cpp:106] Iteration 2500, lr = 8.45897e-05
I0321 20:59:35.982537  6540 solver.cpp:228] Iteration 2600, loss = 0.585699
I0321 20:59:35.982664  6540 solver.cpp:244]     Train net output #0: loss = 0.585699 (* 1 = 0.585699 loss)
I0321 20:59:35.982673  6540 sgd_solver.cpp:106] Iteration 2600, lr = 8.40857e-05
I0321 21:00:08.113782  6540 solver.cpp:228] Iteration 2700, loss = 0.56464
I0321 21:00:08.113873  6540 solver.cpp:244]     Train net output #0: loss = 0.56464 (* 1 = 0.56464 loss)
I0321 21:00:08.113890  6540 sgd_solver.cpp:106] Iteration 2700, lr = 8.35886e-05
I0321 21:00:40.301874  6540 solver.cpp:228] Iteration 2800, loss = 0.568026
I0321 21:00:40.301947  6540 solver.cpp:244]     Train net output #0: loss = 0.568026 (* 1 = 0.568026 loss)
I0321 21:00:40.301955  6540 sgd_solver.cpp:106] Iteration 2800, lr = 8.30984e-05
I0321 21:01:12.394574  6540 solver.cpp:228] Iteration 2900, loss = 0.571242
I0321 21:01:12.394672  6540 solver.cpp:244]     Train net output #0: loss = 0.571242 (* 1 = 0.571242 loss)
I0321 21:01:12.394680  6540 sgd_solver.cpp:106] Iteration 2900, lr = 8.26148e-05
I0321 21:01:44.241030  6540 solver.cpp:337] Iteration 3000, Testing net (#0)
I0321 21:01:44.900586  6540 solver.cpp:404]     Test net output #0: accuracy = 0.82332
I0321 21:01:44.900612  6540 solver.cpp:404]     Test net output #1: loss = 0.573492 (* 1 = 0.573492 loss)
I0321 21:01:45.033037  6540 solver.cpp:228] Iteration 3000, loss = 0.568052
I0321 21:01:45.033072  6540 solver.cpp:244]     Train net output #0: loss = 0.568052 (* 1 = 0.568052 loss)
I0321 21:01:45.033080  6540 sgd_solver.cpp:106] Iteration 3000, lr = 8.21377e-05
I0321 21:02:17.151779  6540 solver.cpp:228] Iteration 3100, loss = 0.546539
I0321 21:02:17.151872  6540 solver.cpp:244]     Train net output #0: loss = 0.546539 (* 1 = 0.546539 loss)
I0321 21:02:17.151880  6540 sgd_solver.cpp:106] Iteration 3100, lr = 8.1667e-05
I0321 21:02:49.302734  6540 solver.cpp:228] Iteration 3200, loss = 0.552444
I0321 21:02:49.302805  6540 solver.cpp:244]     Train net output #0: loss = 0.552444 (* 1 = 0.552444 loss)
I0321 21:02:49.302814  6540 sgd_solver.cpp:106] Iteration 3200, lr = 8.12025e-05
I0321 21:03:21.440832  6540 solver.cpp:228] Iteration 3300, loss = 0.555721
I0321 21:03:21.440929  6540 solver.cpp:244]     Train net output #0: loss = 0.555721 (* 1 = 0.555721 loss)
I0321 21:03:21.440937  6540 sgd_solver.cpp:106] Iteration 3300, lr = 8.07442e-05
I0321 21:03:53.579437  6540 solver.cpp:228] Iteration 3400, loss = 0.557674
I0321 21:03:53.579502  6540 solver.cpp:244]     Train net output #0: loss = 0.557674 (* 1 = 0.557674 loss)
I0321 21:03:53.579510  6540 sgd_solver.cpp:106] Iteration 3400, lr = 8.02918e-05
I0321 21:04:25.506211  6540 solver.cpp:337] Iteration 3500, Testing net (#0)
I0321 21:04:26.167943  6540 solver.cpp:404]     Test net output #0: accuracy = 0.82942
I0321 21:04:26.167976  6540 solver.cpp:404]     Test net output #1: loss = 0.55415 (* 1 = 0.55415 loss)
I0321 21:04:26.300446  6540 solver.cpp:228] Iteration 3500, loss = 0.528877
I0321 21:04:26.300482  6540 solver.cpp:244]     Train net output #0: loss = 0.528877 (* 1 = 0.528877 loss)
I0321 21:04:26.300489  6540 sgd_solver.cpp:106] Iteration 3500, lr = 7.98454e-05
I0321 21:04:58.397133  6540 solver.cpp:228] Iteration 3600, loss = 0.536489
I0321 21:04:58.397207  6540 solver.cpp:244]     Train net output #0: loss = 0.536489 (* 1 = 0.536489 loss)
I0321 21:04:58.397214  6540 sgd_solver.cpp:106] Iteration 3600, lr = 7.94046e-05
I0321 21:05:30.536941  6540 solver.cpp:228] Iteration 3700, loss = 0.542119
I0321 21:05:30.536994  6540 solver.cpp:244]     Train net output #0: loss = 0.542119 (* 1 = 0.542119 loss)
I0321 21:05:30.537003  6540 sgd_solver.cpp:106] Iteration 3700, lr = 7.89695e-05
I0321 21:06:02.653946  6540 solver.cpp:228] Iteration 3800, loss = 0.543738
I0321 21:06:02.654472  6540 solver.cpp:244]     Train net output #0: loss = 0.543738 (* 1 = 0.543738 loss)
I0321 21:06:02.654480  6540 sgd_solver.cpp:106] Iteration 3800, lr = 7.854e-05
I0321 21:06:34.833812  6540 solver.cpp:228] Iteration 3900, loss = 0.516444
I0321 21:06:34.833910  6540 solver.cpp:244]     Train net output #0: loss = 0.516444 (* 1 = 0.516444 loss)
I0321 21:06:34.833919  6540 sgd_solver.cpp:106] Iteration 3900, lr = 7.81158e-05
I0321 21:07:06.971886  6540 solver.cpp:337] Iteration 4000, Testing net (#0)
I0321 21:07:07.658457  6540 solver.cpp:404]     Test net output #0: accuracy = 0.834
I0321 21:07:07.658512  6540 solver.cpp:404]     Test net output #1: loss = 0.53975 (* 1 = 0.53975 loss)
I0321 21:07:07.796362  6540 solver.cpp:228] Iteration 4000, loss = 0.525729
I0321 21:07:07.796423  6540 solver.cpp:244]     Train net output #0: loss = 0.525729 (* 1 = 0.525729 loss)
I0321 21:07:07.796442  6540 sgd_solver.cpp:106] Iteration 4000, lr = 7.76969e-05
I0321 21:07:40.902521  6540 solver.cpp:228] Iteration 4100, loss = 0.529453
I0321 21:07:40.902614  6540 solver.cpp:244]     Train net output #0: loss = 0.529453 (* 1 = 0.529453 loss)
I0321 21:07:40.902631  6540 sgd_solver.cpp:106] Iteration 4100, lr = 7.72833e-05
I0321 21:08:13.110640  6540 solver.cpp:228] Iteration 4200, loss = 0.531621
I0321 21:08:13.110735  6540 solver.cpp:244]     Train net output #0: loss = 0.531621 (* 1 = 0.531621 loss)
I0321 21:08:13.110743  6540 sgd_solver.cpp:106] Iteration 4200, lr = 7.68748e-05
I0321 21:08:45.319334  6540 solver.cpp:228] Iteration 4300, loss = 0.506542
I0321 21:08:45.319418  6540 solver.cpp:244]     Train net output #0: loss = 0.506542 (* 1 = 0.506542 loss)
I0321 21:08:45.319434  6540 sgd_solver.cpp:106] Iteration 4300, lr = 7.64712e-05
I0321 21:09:20.071539  6540 solver.cpp:228] Iteration 4400, loss = 0.516726
I0321 21:09:20.071614  6540 solver.cpp:244]     Train net output #0: loss = 0.516726 (* 1 = 0.516726 loss)
I0321 21:09:20.071624  6540 sgd_solver.cpp:106] Iteration 4400, lr = 7.60726e-05
I0321 21:09:53.072322  6540 solver.cpp:337] Iteration 4500, Testing net (#0)
I0321 21:09:53.793339  6540 solver.cpp:404]     Test net output #0: accuracy = 0.83786
I0321 21:09:53.793366  6540 solver.cpp:404]     Test net output #1: loss = 0.526742 (* 1 = 0.526742 loss)
I0321 21:09:53.932579  6540 solver.cpp:228] Iteration 4500, loss = 0.518638
I0321 21:09:53.932617  6540 solver.cpp:244]     Train net output #0: loss = 0.518638 (* 1 = 0.518638 loss)
I0321 21:09:53.932624  6540 sgd_solver.cpp:106] Iteration 4500, lr = 7.56788e-05
I0321 21:10:28.116869  6540 solver.cpp:228] Iteration 4600, loss = 0.521806
I0321 21:10:28.116927  6540 solver.cpp:244]     Train net output #0: loss = 0.521806 (* 1 = 0.521806 loss)
I0321 21:10:28.116935  6540 sgd_solver.cpp:106] Iteration 4600, lr = 7.52897e-05
I0321 21:11:02.010174  6540 solver.cpp:228] Iteration 4700, loss = 0.498966
I0321 21:11:02.010246  6540 solver.cpp:244]     Train net output #0: loss = 0.498966 (* 1 = 0.498966 loss)
I0321 21:11:02.010259  6540 sgd_solver.cpp:106] Iteration 4700, lr = 7.49052e-05
I0321 21:11:35.199573  6540 solver.cpp:228] Iteration 4800, loss = 0.504053
I0321 21:11:35.199642  6540 solver.cpp:244]     Train net output #0: loss = 0.504053 (* 1 = 0.504053 loss)
I0321 21:11:35.199658  6540 sgd_solver.cpp:106] Iteration 4800, lr = 7.45253e-05
I0321 21:12:08.491435  6540 solver.cpp:228] Iteration 4900, loss = 0.508099
I0321 21:12:08.491511  6540 solver.cpp:244]     Train net output #0: loss = 0.508099 (* 1 = 0.508099 loss)
I0321 21:12:08.491523  6540 sgd_solver.cpp:106] Iteration 4900, lr = 7.41499e-05
I0321 21:12:40.121564  6540 solver.cpp:454] Snapshotting to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_5000.caffemodel
I0321 21:12:40.319824  6540 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_5000.solverstate
I0321 21:12:40.321633  6540 solver.cpp:337] Iteration 5000, Testing net (#0)
I0321 21:12:40.806243  6540 solver.cpp:404]     Test net output #0: accuracy = 0.84066
I0321 21:12:40.806282  6540 solver.cpp:404]     Test net output #1: loss = 0.515551 (* 1 = 0.515551 loss)
I0321 21:12:40.939081  6540 solver.cpp:228] Iteration 5000, loss = 0.512866
I0321 21:12:40.939117  6540 solver.cpp:244]     Train net output #0: loss = 0.512866 (* 1 = 0.512866 loss)
I0321 21:12:40.939124  6540 sgd_solver.cpp:106] Iteration 5000, lr = 7.37788e-05
I0321 21:13:13.149060  6540 solver.cpp:228] Iteration 5100, loss = 0.491305
I0321 21:13:13.149175  6540 solver.cpp:244]     Train net output #0: loss = 0.491305 (* 1 = 0.491305 loss)
I0321 21:13:13.149183  6540 sgd_solver.cpp:106] Iteration 5100, lr = 7.3412e-05
I0321 21:13:45.563706  6540 solver.cpp:228] Iteration 5200, loss = 0.495059
I0321 21:13:45.563802  6540 solver.cpp:244]     Train net output #0: loss = 0.495059 (* 1 = 0.495059 loss)
I0321 21:13:45.563808  6540 sgd_solver.cpp:106] Iteration 5200, lr = 7.30495e-05
I0321 21:14:18.749953  6540 solver.cpp:228] Iteration 5300, loss = 0.498943
I0321 21:14:18.750046  6540 solver.cpp:244]     Train net output #0: loss = 0.498943 (* 1 = 0.498943 loss)
I0321 21:14:18.750064  6540 sgd_solver.cpp:106] Iteration 5300, lr = 7.26911e-05
I0321 21:14:52.011927  6540 solver.cpp:228] Iteration 5400, loss = 0.504836
I0321 21:14:52.012006  6540 solver.cpp:244]     Train net output #0: loss = 0.504836 (* 1 = 0.504836 loss)
I0321 21:14:52.012013  6540 sgd_solver.cpp:106] Iteration 5400, lr = 7.23368e-05
I0321 21:15:24.259016  6540 solver.cpp:337] Iteration 5500, Testing net (#0)
I0321 21:15:24.969748  6540 solver.cpp:404]     Test net output #0: accuracy = 0.84366
I0321 21:15:24.969777  6540 solver.cpp:404]     Test net output #1: loss = 0.505232 (* 1 = 0.505232 loss)
I0321 21:15:25.102262  6540 solver.cpp:228] Iteration 5500, loss = 0.485953
I0321 21:15:25.102288  6540 solver.cpp:244]     Train net output #0: loss = 0.485953 (* 1 = 0.485953 loss)
I0321 21:15:25.102296  6540 sgd_solver.cpp:106] Iteration 5500, lr = 7.19865e-05
I0321 21:15:57.586016  6540 solver.cpp:228] Iteration 5600, loss = 0.487779
I0321 21:15:57.586087  6540 solver.cpp:244]     Train net output #0: loss = 0.487779 (* 1 = 0.487779 loss)
I0321 21:15:57.586096  6540 sgd_solver.cpp:106] Iteration 5600, lr = 7.16402e-05
I0321 21:16:29.864238  6540 solver.cpp:228] Iteration 5700, loss = 0.49227
I0321 21:16:29.864326  6540 solver.cpp:244]     Train net output #0: loss = 0.49227 (* 1 = 0.49227 loss)
I0321 21:16:29.864346  6540 sgd_solver.cpp:106] Iteration 5700, lr = 7.12977e-05
I0321 21:17:02.802955  6540 solver.cpp:228] Iteration 5800, loss = 0.497424
I0321 21:17:02.803040  6540 solver.cpp:244]     Train net output #0: loss = 0.497424 (* 1 = 0.497424 loss)
I0321 21:17:02.803058  6540 sgd_solver.cpp:106] Iteration 5800, lr = 7.0959e-05
I0321 21:17:35.140023  6540 solver.cpp:228] Iteration 5900, loss = 0.479228
I0321 21:17:35.140111  6540 solver.cpp:244]     Train net output #0: loss = 0.479228 (* 1 = 0.479228 loss)
I0321 21:17:35.140130  6540 sgd_solver.cpp:106] Iteration 5900, lr = 7.0624e-05
I0321 21:18:07.195516  6540 solver.cpp:337] Iteration 6000, Testing net (#0)
I0321 21:18:07.915769  6540 solver.cpp:404]     Test net output #0: accuracy = 0.84624
I0321 21:18:07.915830  6540 solver.cpp:404]     Test net output #1: loss = 0.497149 (* 1 = 0.497149 loss)
I0321 21:18:08.048935  6540 solver.cpp:228] Iteration 6000, loss = 0.479123
I0321 21:18:08.048995  6540 solver.cpp:244]     Train net output #0: loss = 0.479123 (* 1 = 0.479123 loss)
I0321 21:18:08.049005  6540 sgd_solver.cpp:106] Iteration 6000, lr = 7.02927e-05
I0321 21:18:40.440363  6540 solver.cpp:228] Iteration 6100, loss = 0.487366
I0321 21:18:40.440415  6540 solver.cpp:244]     Train net output #0: loss = 0.487366 (* 1 = 0.487366 loss)
I0321 21:18:40.440423  6540 sgd_solver.cpp:106] Iteration 6100, lr = 6.9965e-05
I0321 21:19:14.433018  6540 solver.cpp:228] Iteration 6200, loss = 0.488845
I0321 21:19:14.433349  6540 solver.cpp:244]     Train net output #0: loss = 0.488845 (* 1 = 0.488845 loss)
I0321 21:19:14.433357  6540 sgd_solver.cpp:106] Iteration 6200, lr = 6.96408e-05
I0321 21:19:47.310518  6540 solver.cpp:228] Iteration 6300, loss = 0.475955
I0321 21:19:47.310585  6540 solver.cpp:244]     Train net output #0: loss = 0.475955 (* 1 = 0.475955 loss)
I0321 21:19:47.310596  6540 sgd_solver.cpp:106] Iteration 6300, lr = 6.93201e-05
I0321 21:20:20.711161  6540 solver.cpp:228] Iteration 6400, loss = 0.475011
I0321 21:20:20.711231  6540 solver.cpp:244]     Train net output #0: loss = 0.475011 (* 1 = 0.475011 loss)
I0321 21:20:20.711246  6540 sgd_solver.cpp:106] Iteration 6400, lr = 6.90029e-05
I0321 21:20:53.138680  6540 solver.cpp:337] Iteration 6500, Testing net (#0)
I0321 21:20:53.866660  6540 solver.cpp:404]     Test net output #0: accuracy = 0.848
I0321 21:20:53.866698  6540 solver.cpp:404]     Test net output #1: loss = 0.48966 (* 1 = 0.48966 loss)
I0321 21:20:53.997226  6540 solver.cpp:228] Iteration 6500, loss = 0.481637
I0321 21:20:53.997251  6540 solver.cpp:244]     Train net output #0: loss = 0.481637 (* 1 = 0.481637 loss)
I0321 21:20:53.997261  6540 sgd_solver.cpp:106] Iteration 6500, lr = 6.8689e-05
I0321 21:21:26.622509  6540 solver.cpp:228] Iteration 6600, loss = 0.483971
I0321 21:21:26.622576  6540 solver.cpp:244]     Train net output #0: loss = 0.483971 (* 1 = 0.483971 loss)
I0321 21:21:26.622584  6540 sgd_solver.cpp:106] Iteration 6600, lr = 6.83784e-05
I0321 21:21:58.812527  6540 solver.cpp:228] Iteration 6700, loss = 0.468279
I0321 21:21:58.812579  6540 solver.cpp:244]     Train net output #0: loss = 0.468279 (* 1 = 0.468279 loss)
I0321 21:21:58.812587  6540 sgd_solver.cpp:106] Iteration 6700, lr = 6.80711e-05
I0321 21:22:30.982595  6540 solver.cpp:228] Iteration 6800, loss = 0.469157
I0321 21:22:30.982662  6540 solver.cpp:244]     Train net output #0: loss = 0.469157 (* 1 = 0.469157 loss)
I0321 21:22:30.982673  6540 sgd_solver.cpp:106] Iteration 6800, lr = 6.7767e-05
I0321 21:23:03.336839  6540 solver.cpp:228] Iteration 6900, loss = 0.47493
I0321 21:23:03.336889  6540 solver.cpp:244]     Train net output #0: loss = 0.47493 (* 1 = 0.47493 loss)
I0321 21:23:03.336896  6540 sgd_solver.cpp:106] Iteration 6900, lr = 6.7466e-05
I0321 21:23:35.223495  6540 solver.cpp:337] Iteration 7000, Testing net (#0)
I0321 21:23:35.903102  6540 solver.cpp:404]     Test net output #0: accuracy = 0.85088
I0321 21:23:35.903127  6540 solver.cpp:404]     Test net output #1: loss = 0.482381 (* 1 = 0.482381 loss)
I0321 21:23:36.041064  6540 solver.cpp:228] Iteration 7000, loss = 0.47613
I0321 21:23:36.041101  6540 solver.cpp:244]     Train net output #0: loss = 0.47613 (* 1 = 0.47613 loss)
I0321 21:23:36.041108  6540 sgd_solver.cpp:106] Iteration 7000, lr = 6.71681e-05
I0321 21:24:08.207393  6540 solver.cpp:228] Iteration 7100, loss = 0.465792
I0321 21:24:08.207482  6540 solver.cpp:244]     Train net output #0: loss = 0.465792 (* 1 = 0.465792 loss)
I0321 21:24:08.207490  6540 sgd_solver.cpp:106] Iteration 7100, lr = 6.68733e-05
I0321 21:24:40.620880  6540 solver.cpp:228] Iteration 7200, loss = 0.46033
I0321 21:24:40.620967  6540 solver.cpp:244]     Train net output #0: loss = 0.46033 (* 1 = 0.46033 loss)
I0321 21:24:40.620976  6540 sgd_solver.cpp:106] Iteration 7200, lr = 6.65815e-05
I0321 21:25:13.104524  6540 solver.cpp:228] Iteration 7300, loss = 0.47061
I0321 21:25:13.104614  6540 solver.cpp:244]     Train net output #0: loss = 0.47061 (* 1 = 0.47061 loss)
I0321 21:25:13.104621  6540 sgd_solver.cpp:106] Iteration 7300, lr = 6.62927e-05
I0321 21:25:45.524550  6540 solver.cpp:228] Iteration 7400, loss = 0.470051
I0321 21:25:45.524642  6540 solver.cpp:244]     Train net output #0: loss = 0.470051 (* 1 = 0.470051 loss)
I0321 21:25:45.524649  6540 sgd_solver.cpp:106] Iteration 7400, lr = 6.60067e-05
I0321 21:26:17.426415  6540 solver.cpp:337] Iteration 7500, Testing net (#0)
I0321 21:26:18.104769  6540 solver.cpp:404]     Test net output #0: accuracy = 0.85298
I0321 21:26:18.104804  6540 solver.cpp:404]     Test net output #1: loss = 0.475675 (* 1 = 0.475675 loss)
I0321 21:26:18.240322  6540 solver.cpp:228] Iteration 7500, loss = 0.459174
I0321 21:26:18.240357  6540 solver.cpp:244]     Train net output #0: loss = 0.459174 (* 1 = 0.459174 loss)
I0321 21:26:18.240363  6540 sgd_solver.cpp:106] Iteration 7500, lr = 6.57236e-05
I0321 21:26:50.665019  6540 solver.cpp:228] Iteration 7600, loss = 0.455276
I0321 21:26:50.665081  6540 solver.cpp:244]     Train net output #0: loss = 0.455276 (* 1 = 0.455276 loss)
I0321 21:26:50.665088  6540 sgd_solver.cpp:106] Iteration 7600, lr = 6.54433e-05
I0321 21:27:23.254875  6540 solver.cpp:228] Iteration 7700, loss = 0.464112
I0321 21:27:23.254982  6540 solver.cpp:244]     Train net output #0: loss = 0.464112 (* 1 = 0.464112 loss)
I0321 21:27:23.255000  6540 sgd_solver.cpp:106] Iteration 7700, lr = 6.51658e-05
I0321 21:27:55.528632  6540 solver.cpp:228] Iteration 7800, loss = 0.466518
I0321 21:27:55.528702  6540 solver.cpp:244]     Train net output #0: loss = 0.466518 (* 1 = 0.466518 loss)
I0321 21:27:55.528709  6540 sgd_solver.cpp:106] Iteration 7800, lr = 6.48911e-05
I0321 21:28:27.816787  6540 solver.cpp:228] Iteration 7900, loss = 0.455766
I0321 21:28:27.817627  6540 solver.cpp:244]     Train net output #0: loss = 0.455766 (* 1 = 0.455766 loss)
I0321 21:28:27.817636  6540 sgd_solver.cpp:106] Iteration 7900, lr = 6.4619e-05
I0321 21:29:00.432570  6540 solver.cpp:337] Iteration 8000, Testing net (#0)
I0321 21:29:01.156158  6540 solver.cpp:404]     Test net output #0: accuracy = 0.85516
I0321 21:29:01.156198  6540 solver.cpp:404]     Test net output #1: loss = 0.470135 (* 1 = 0.470135 loss)
I0321 21:29:01.287859  6540 solver.cpp:228] Iteration 8000, loss = 0.451916
I0321 21:29:01.287899  6540 solver.cpp:244]     Train net output #0: loss = 0.451916 (* 1 = 0.451916 loss)
I0321 21:29:01.287905  6540 sgd_solver.cpp:106] Iteration 8000, lr = 6.43496e-05
I0321 21:29:34.248075  6540 solver.cpp:228] Iteration 8100, loss = 0.457616
I0321 21:29:34.248186  6540 solver.cpp:244]     Train net output #0: loss = 0.457616 (* 1 = 0.457616 loss)
I0321 21:29:34.248193  6540 sgd_solver.cpp:106] Iteration 8100, lr = 6.40827e-05
I0321 21:30:07.289697  6540 solver.cpp:228] Iteration 8200, loss = 0.462552
I0321 21:30:07.289753  6540 solver.cpp:244]     Train net output #0: loss = 0.462552 (* 1 = 0.462552 loss)
I0321 21:30:07.289760  6540 sgd_solver.cpp:106] Iteration 8200, lr = 6.38185e-05
I0321 21:30:40.769712  6540 solver.cpp:228] Iteration 8300, loss = 0.450512
I0321 21:30:40.769815  6540 solver.cpp:244]     Train net output #0: loss = 0.450512 (* 1 = 0.450512 loss)
I0321 21:30:40.769835  6540 sgd_solver.cpp:106] Iteration 8300, lr = 6.35567e-05
I0321 21:31:14.398890  6540 solver.cpp:228] Iteration 8400, loss = 0.44469
I0321 21:31:14.398959  6540 solver.cpp:244]     Train net output #0: loss = 0.44469 (* 1 = 0.44469 loss)
I0321 21:31:14.398970  6540 sgd_solver.cpp:106] Iteration 8400, lr = 6.32975e-05
I0321 21:31:46.726593  6540 solver.cpp:337] Iteration 8500, Testing net (#0)
I0321 21:31:47.422971  6540 solver.cpp:404]     Test net output #0: accuracy = 0.85682
I0321 21:31:47.423007  6540 solver.cpp:404]     Test net output #1: loss = 0.464592 (* 1 = 0.464592 loss)
I0321 21:31:47.557801  6540 solver.cpp:228] Iteration 8500, loss = 0.452881
I0321 21:31:47.557826  6540 solver.cpp:244]     Train net output #0: loss = 0.452881 (* 1 = 0.452881 loss)
I0321 21:31:47.557833  6540 sgd_solver.cpp:106] Iteration 8500, lr = 6.30407e-05
I0321 21:32:20.102126  6540 solver.cpp:228] Iteration 8600, loss = 0.458821
I0321 21:32:20.102221  6540 solver.cpp:244]     Train net output #0: loss = 0.458821 (* 1 = 0.458821 loss)
I0321 21:32:20.102227  6540 sgd_solver.cpp:106] Iteration 8600, lr = 6.27864e-05
I0321 21:32:52.655720  6540 solver.cpp:228] Iteration 8700, loss = 0.446434
I0321 21:32:52.655787  6540 solver.cpp:244]     Train net output #0: loss = 0.446434 (* 1 = 0.446434 loss)
I0321 21:32:52.655797  6540 sgd_solver.cpp:106] Iteration 8700, lr = 6.25344e-05
I0321 21:33:24.945037  6540 solver.cpp:228] Iteration 8800, loss = 0.436476
I0321 21:33:24.945108  6540 solver.cpp:244]     Train net output #0: loss = 0.436476 (* 1 = 0.436476 loss)
I0321 21:33:24.945117  6540 sgd_solver.cpp:106] Iteration 8800, lr = 6.22847e-05
I0321 21:33:57.342063  6540 solver.cpp:228] Iteration 8900, loss = 0.449703
I0321 21:33:57.342116  6540 solver.cpp:244]     Train net output #0: loss = 0.449703 (* 1 = 0.449703 loss)
I0321 21:33:57.342126  6540 sgd_solver.cpp:106] Iteration 8900, lr = 6.20374e-05
I0321 21:34:29.822053  6540 solver.cpp:337] Iteration 9000, Testing net (#0)
I0321 21:34:30.561002  6540 solver.cpp:404]     Test net output #0: accuracy = 0.85836
I0321 21:34:30.561069  6540 solver.cpp:404]     Test net output #1: loss = 0.459032 (* 1 = 0.459032 loss)
I0321 21:34:30.698866  6540 solver.cpp:228] Iteration 9000, loss = 0.454438
I0321 21:34:30.698930  6540 solver.cpp:244]     Train net output #0: loss = 0.454438 (* 1 = 0.454438 loss)
I0321 21:34:30.698949  6540 sgd_solver.cpp:106] Iteration 9000, lr = 6.17924e-05
I0321 21:35:04.008725  6540 solver.cpp:228] Iteration 9100, loss = 0.443773
I0321 21:35:04.008796  6540 solver.cpp:244]     Train net output #0: loss = 0.443773 (* 1 = 0.443773 loss)
I0321 21:35:04.008816  6540 sgd_solver.cpp:106] Iteration 9100, lr = 6.15496e-05
I0321 21:35:38.423622  6540 solver.cpp:228] Iteration 9200, loss = 0.43257
I0321 21:35:38.423696  6540 solver.cpp:244]     Train net output #0: loss = 0.43257 (* 1 = 0.43257 loss)
I0321 21:35:38.423707  6540 sgd_solver.cpp:106] Iteration 9200, lr = 6.1309e-05
I0321 21:36:11.588161  6540 solver.cpp:228] Iteration 9300, loss = 0.446064
I0321 21:36:11.588228  6540 solver.cpp:244]     Train net output #0: loss = 0.446064 (* 1 = 0.446064 loss)
I0321 21:36:11.588240  6540 sgd_solver.cpp:106] Iteration 9300, lr = 6.10706e-05
I0321 21:36:44.730965  6540 solver.cpp:228] Iteration 9400, loss = 0.448165
I0321 21:36:44.731025  6540 solver.cpp:244]     Train net output #0: loss = 0.448165 (* 1 = 0.448165 loss)
I0321 21:36:44.731036  6540 sgd_solver.cpp:106] Iteration 9400, lr = 6.08343e-05
I0321 21:37:17.592160  6540 solver.cpp:337] Iteration 9500, Testing net (#0)
I0321 21:37:18.391104  6540 solver.cpp:404]     Test net output #0: accuracy = 0.8593
I0321 21:37:18.391132  6540 solver.cpp:404]     Test net output #1: loss = 0.454833 (* 1 = 0.454833 loss)
I0321 21:37:18.531147  6540 solver.cpp:228] Iteration 9500, loss = 0.438006
I0321 21:37:18.531173  6540 solver.cpp:244]     Train net output #0: loss = 0.438006 (* 1 = 0.438006 loss)
I0321 21:37:18.531180  6540 sgd_solver.cpp:106] Iteration 9500, lr = 6.06002e-05
I0321 21:37:51.208886  6540 solver.cpp:228] Iteration 9600, loss = 0.427496
I0321 21:37:51.208957  6540 solver.cpp:244]     Train net output #0: loss = 0.427496 (* 1 = 0.427496 loss)
I0321 21:37:51.209018  6540 sgd_solver.cpp:106] Iteration 9600, lr = 6.03682e-05
I0321 21:38:23.232396  6540 solver.cpp:228] Iteration 9700, loss = 0.44292
I0321 21:38:23.232462  6540 solver.cpp:244]     Train net output #0: loss = 0.44292 (* 1 = 0.44292 loss)
I0321 21:38:23.232472  6540 sgd_solver.cpp:106] Iteration 9700, lr = 6.01382e-05
I0321 21:38:55.335831  6540 solver.cpp:228] Iteration 9800, loss = 0.445606
I0321 21:38:55.335903  6540 solver.cpp:244]     Train net output #0: loss = 0.445606 (* 1 = 0.445606 loss)
I0321 21:38:55.335913  6540 sgd_solver.cpp:106] Iteration 9800, lr = 5.99102e-05
I0321 21:39:27.279326  6540 solver.cpp:228] Iteration 9900, loss = 0.43868
I0321 21:39:27.279407  6540 solver.cpp:244]     Train net output #0: loss = 0.43868 (* 1 = 0.43868 loss)
I0321 21:39:27.279414  6540 sgd_solver.cpp:106] Iteration 9900, lr = 5.96843e-05
I0321 21:39:59.029896  6540 solver.cpp:454] Snapshotting to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_10000.caffemodel
I0321 21:39:59.223378  6540 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_10000.solverstate
I0321 21:39:59.225181  6540 solver.cpp:337] Iteration 10000, Testing net (#0)
I0321 21:39:59.714476  6540 solver.cpp:404]     Test net output #0: accuracy = 0.86038
I0321 21:39:59.714505  6540 solver.cpp:404]     Test net output #1: loss = 0.450402 (* 1 = 0.450402 loss)
I0321 21:39:59.846452  6540 solver.cpp:228] Iteration 10000, loss = 0.422518
I0321 21:39:59.846498  6540 solver.cpp:244]     Train net output #0: loss = 0.422518 (* 1 = 0.422518 loss)
I0321 21:39:59.846505  6540 sgd_solver.cpp:106] Iteration 10000, lr = 5.94604e-05
I0321 21:40:32.159150  6540 solver.cpp:228] Iteration 10100, loss = 0.437054
I0321 21:40:32.159273  6540 solver.cpp:244]     Train net output #0: loss = 0.437054 (* 1 = 0.437054 loss)
I0321 21:40:32.159281  6540 sgd_solver.cpp:106] Iteration 10100, lr = 5.92383e-05
I0321 21:41:04.429826  6540 solver.cpp:228] Iteration 10200, loss = 0.443085
I0321 21:41:04.429903  6540 solver.cpp:244]     Train net output #0: loss = 0.443085 (* 1 = 0.443085 loss)
I0321 21:41:04.429920  6540 sgd_solver.cpp:106] Iteration 10200, lr = 5.90183e-05
I0321 21:41:36.683893  6540 solver.cpp:228] Iteration 10300, loss = 0.438531
I0321 21:41:36.683993  6540 solver.cpp:244]     Train net output #0: loss = 0.438531 (* 1 = 0.438531 loss)
I0321 21:41:36.684015  6540 sgd_solver.cpp:106] Iteration 10300, lr = 5.88001e-05
I0321 21:42:08.994966  6540 solver.cpp:228] Iteration 10400, loss = 0.417805
I0321 21:42:08.995034  6540 solver.cpp:244]     Train net output #0: loss = 0.417805 (* 1 = 0.417805 loss)
I0321 21:42:08.995043  6540 sgd_solver.cpp:106] Iteration 10400, lr = 5.85838e-05
I0321 21:42:40.947561  6540 solver.cpp:337] Iteration 10500, Testing net (#0)
I0321 21:42:41.605996  6540 solver.cpp:404]     Test net output #0: accuracy = 0.8618
I0321 21:42:41.606034  6540 solver.cpp:404]     Test net output #1: loss = 0.445665 (* 1 = 0.445665 loss)
I0321 21:42:41.738840  6540 solver.cpp:228] Iteration 10500, loss = 0.434818
I0321 21:42:41.738867  6540 solver.cpp:244]     Train net output #0: loss = 0.434818 (* 1 = 0.434818 loss)
I0321 21:42:41.738873  6540 sgd_solver.cpp:106] Iteration 10500, lr = 5.83693e-05
I0321 21:43:13.964990  6540 solver.cpp:228] Iteration 10600, loss = 0.436793
I0321 21:43:13.965112  6540 solver.cpp:244]     Train net output #0: loss = 0.436793 (* 1 = 0.436793 loss)
I0321 21:43:13.965131  6540 sgd_solver.cpp:106] Iteration 10600, lr = 5.81567e-05
I0321 21:43:46.196367  6540 solver.cpp:228] Iteration 10700, loss = 0.435461
I0321 21:43:46.196449  6540 solver.cpp:244]     Train net output #0: loss = 0.435461 (* 1 = 0.435461 loss)
I0321 21:43:46.196465  6540 sgd_solver.cpp:106] Iteration 10700, lr = 5.79458e-05
I0321 21:44:18.448765  6540 solver.cpp:228] Iteration 10800, loss = 0.414889
I0321 21:44:18.448848  6540 solver.cpp:244]     Train net output #0: loss = 0.414889 (* 1 = 0.414889 loss)
I0321 21:44:18.448855  6540 sgd_solver.cpp:106] Iteration 10800, lr = 5.77368e-05
I0321 21:44:50.743314  6540 solver.cpp:228] Iteration 10900, loss = 0.432221
I0321 21:44:50.743374  6540 solver.cpp:244]     Train net output #0: loss = 0.432221 (* 1 = 0.432221 loss)
I0321 21:44:50.743381  6540 sgd_solver.cpp:106] Iteration 10900, lr = 5.75295e-05
I0321 21:45:22.602205  6540 solver.cpp:337] Iteration 11000, Testing net (#0)
I0321 21:45:23.268172  6540 solver.cpp:404]     Test net output #0: accuracy = 0.86318
I0321 21:45:23.268198  6540 solver.cpp:404]     Test net output #1: loss = 0.442903 (* 1 = 0.442903 loss)
I0321 21:45:23.401224  6540 solver.cpp:228] Iteration 11000, loss = 0.435826
I0321 21:45:23.401248  6540 solver.cpp:244]     Train net output #0: loss = 0.435826 (* 1 = 0.435826 loss)
I0321 21:45:23.401255  6540 sgd_solver.cpp:106] Iteration 11000, lr = 5.73239e-05
I0321 21:45:55.693903  6540 solver.cpp:228] Iteration 11100, loss = 0.433905
I0321 21:45:55.693980  6540 solver.cpp:244]     Train net output #0: loss = 0.433905 (* 1 = 0.433905 loss)
I0321 21:45:55.693997  6540 sgd_solver.cpp:106] Iteration 11100, lr = 5.712e-05
I0321 21:46:27.924849  6540 solver.cpp:228] Iteration 11200, loss = 0.411351
I0321 21:46:27.925448  6540 solver.cpp:244]     Train net output #0: loss = 0.411351 (* 1 = 0.411351 loss)
I0321 21:46:27.925457  6540 sgd_solver.cpp:106] Iteration 11200, lr = 5.69178e-05
I0321 21:47:00.162482  6540 solver.cpp:228] Iteration 11300, loss = 0.4271
I0321 21:47:00.162600  6540 solver.cpp:244]     Train net output #0: loss = 0.4271 (* 1 = 0.4271 loss)
I0321 21:47:00.162617  6540 sgd_solver.cpp:106] Iteration 11300, lr = 5.67173e-05
I0321 21:47:32.433456  6540 solver.cpp:228] Iteration 11400, loss = 0.430907
I0321 21:47:32.433526  6540 solver.cpp:244]     Train net output #0: loss = 0.430907 (* 1 = 0.430907 loss)
I0321 21:47:32.433533  6540 sgd_solver.cpp:106] Iteration 11400, lr = 5.65184e-05
I0321 21:48:04.364012  6540 solver.cpp:337] Iteration 11500, Testing net (#0)
I0321 21:48:05.025653  6540 solver.cpp:404]     Test net output #0: accuracy = 0.86392
I0321 21:48:05.025683  6540 solver.cpp:404]     Test net output #1: loss = 0.439105 (* 1 = 0.439105 loss)
I0321 21:48:05.158123  6540 solver.cpp:228] Iteration 11500, loss = 0.431604
I0321 21:48:05.158159  6540 solver.cpp:244]     Train net output #0: loss = 0.431604 (* 1 = 0.431604 loss)
I0321 21:48:05.158166  6540 sgd_solver.cpp:106] Iteration 11500, lr = 5.63211e-05
I0321 21:48:37.382818  6540 solver.cpp:228] Iteration 11600, loss = 0.409483
I0321 21:48:37.382916  6540 solver.cpp:244]     Train net output #0: loss = 0.409483 (* 1 = 0.409483 loss)
I0321 21:48:37.382923  6540 sgd_solver.cpp:106] Iteration 11600, lr = 5.61254e-05
I0321 21:49:09.664827  6540 solver.cpp:228] Iteration 11700, loss = 0.422947
I0321 21:49:09.664890  6540 solver.cpp:244]     Train net output #0: loss = 0.422947 (* 1 = 0.422947 loss)
I0321 21:49:09.664897  6540 sgd_solver.cpp:106] Iteration 11700, lr = 5.59313e-05
I0321 21:49:41.898739  6540 solver.cpp:228] Iteration 11800, loss = 0.427524
I0321 21:49:41.898813  6540 solver.cpp:244]     Train net output #0: loss = 0.427524 (* 1 = 0.427524 loss)
I0321 21:49:41.898821  6540 sgd_solver.cpp:106] Iteration 11800, lr = 5.57388e-05
I0321 21:50:14.033915  6540 solver.cpp:228] Iteration 11900, loss = 0.428568
I0321 21:50:14.033982  6540 solver.cpp:244]     Train net output #0: loss = 0.428568 (* 1 = 0.428568 loss)
I0321 21:50:14.033989  6540 sgd_solver.cpp:106] Iteration 11900, lr = 5.55478e-05
I0321 21:50:45.947809  6540 solver.cpp:337] Iteration 12000, Testing net (#0)
I0321 21:50:46.612431  6540 solver.cpp:404]     Test net output #0: accuracy = 0.8658
I0321 21:50:46.612464  6540 solver.cpp:404]     Test net output #1: loss = 0.434553 (* 1 = 0.434553 loss)
I0321 21:50:46.744992  6540 solver.cpp:228] Iteration 12000, loss = 0.406025
I0321 21:50:46.745028  6540 solver.cpp:244]     Train net output #0: loss = 0.406025 (* 1 = 0.406025 loss)
I0321 21:50:46.745033  6540 sgd_solver.cpp:106] Iteration 12000, lr = 5.53583e-05
I0321 21:51:19.072470  6540 solver.cpp:228] Iteration 12100, loss = 0.422227
I0321 21:51:19.072569  6540 solver.cpp:244]     Train net output #0: loss = 0.422227 (* 1 = 0.422227 loss)
I0321 21:51:19.072576  6540 sgd_solver.cpp:106] Iteration 12100, lr = 5.51704e-05
I0321 21:51:51.303923  6540 solver.cpp:228] Iteration 12200, loss = 0.427939
I0321 21:51:51.303993  6540 solver.cpp:244]     Train net output #0: loss = 0.427939 (* 1 = 0.427939 loss)
I0321 21:51:51.304004  6540 sgd_solver.cpp:106] Iteration 12200, lr = 5.49839e-05
I0321 21:52:23.490386  6540 solver.cpp:228] Iteration 12300, loss = 0.426192
I0321 21:52:23.490485  6540 solver.cpp:244]     Train net output #0: loss = 0.426192 (* 1 = 0.426192 loss)
I0321 21:52:23.490494  6540 sgd_solver.cpp:106] Iteration 12300, lr = 5.47988e-05
I0321 21:52:55.759208  6540 solver.cpp:228] Iteration 12400, loss = 0.403154
I0321 21:52:55.759281  6540 solver.cpp:244]     Train net output #0: loss = 0.403154 (* 1 = 0.403154 loss)
I0321 21:52:55.759289  6540 sgd_solver.cpp:106] Iteration 12400, lr = 5.46153e-05
I0321 21:53:27.627223  6540 solver.cpp:337] Iteration 12500, Testing net (#0)
I0321 21:53:28.294006  6540 solver.cpp:404]     Test net output #0: accuracy = 0.8664
I0321 21:53:28.294046  6540 solver.cpp:404]     Test net output #1: loss = 0.432645 (* 1 = 0.432645 loss)
I0321 21:53:28.426587  6540 solver.cpp:228] Iteration 12500, loss = 0.418051
I0321 21:53:28.426623  6540 solver.cpp:244]     Train net output #0: loss = 0.418051 (* 1 = 0.418051 loss)
I0321 21:53:28.426630  6540 sgd_solver.cpp:106] Iteration 12500, lr = 5.44331e-05
I0321 21:54:00.670164  6540 solver.cpp:228] Iteration 12600, loss = 0.424553
I0321 21:54:00.670251  6540 solver.cpp:244]     Train net output #0: loss = 0.424553 (* 1 = 0.424553 loss)
I0321 21:54:00.670269  6540 sgd_solver.cpp:106] Iteration 12600, lr = 5.42524e-05
I0321 21:54:32.906064  6540 solver.cpp:228] Iteration 12700, loss = 0.42382
I0321 21:54:32.906193  6540 solver.cpp:244]     Train net output #0: loss = 0.42382 (* 1 = 0.42382 loss)
I0321 21:54:32.906201  6540 sgd_solver.cpp:106] Iteration 12700, lr = 5.4073e-05
I0321 21:55:05.126601  6540 solver.cpp:228] Iteration 12800, loss = 0.403151
I0321 21:55:05.126684  6540 solver.cpp:244]     Train net output #0: loss = 0.403151 (* 1 = 0.403151 loss)
I0321 21:55:05.126703  6540 sgd_solver.cpp:106] Iteration 12800, lr = 5.3895e-05
I0321 21:55:37.431457  6540 solver.cpp:228] Iteration 12900, loss = 0.414542
I0321 21:55:37.431538  6540 solver.cpp:244]     Train net output #0: loss = 0.414542 (* 1 = 0.414542 loss)
I0321 21:55:37.431555  6540 sgd_solver.cpp:106] Iteration 12900, lr = 5.37184e-05
I0321 21:56:09.383019  6540 solver.cpp:337] Iteration 13000, Testing net (#0)
I0321 21:56:10.044421  6540 solver.cpp:404]     Test net output #0: accuracy = 0.8676
I0321 21:56:10.044461  6540 solver.cpp:404]     Test net output #1: loss = 0.429064 (* 1 = 0.429064 loss)
I0321 21:56:10.174855  6540 solver.cpp:228] Iteration 13000, loss = 0.420623
I0321 21:56:10.174882  6540 solver.cpp:244]     Train net output #0: loss = 0.420623 (* 1 = 0.420623 loss)
I0321 21:56:10.174888  6540 sgd_solver.cpp:106] Iteration 13000, lr = 5.35432e-05
I0321 21:56:42.326220  6540 solver.cpp:228] Iteration 13100, loss = 0.420097
I0321 21:56:42.326323  6540 solver.cpp:244]     Train net output #0: loss = 0.420097 (* 1 = 0.420097 loss)
I0321 21:56:42.326330  6540 sgd_solver.cpp:106] Iteration 13100, lr = 5.33692e-05
I0321 21:57:14.574980  6540 solver.cpp:228] Iteration 13200, loss = 0.401187
I0321 21:57:14.575083  6540 solver.cpp:244]     Train net output #0: loss = 0.401187 (* 1 = 0.401187 loss)
I0321 21:57:14.575101  6540 sgd_solver.cpp:106] Iteration 13200, lr = 5.31966e-05
I0321 21:57:46.786936  6540 solver.cpp:228] Iteration 13300, loss = 0.411128
I0321 21:57:46.787683  6540 solver.cpp:244]     Train net output #0: loss = 0.411128 (* 1 = 0.411128 loss)
I0321 21:57:46.787690  6540 sgd_solver.cpp:106] Iteration 13300, lr = 5.30253e-05
I0321 21:58:19.063552  6540 solver.cpp:228] Iteration 13400, loss = 0.419775
I0321 21:58:19.063617  6540 solver.cpp:244]     Train net output #0: loss = 0.419775 (* 1 = 0.419775 loss)
I0321 21:58:19.063624  6540 sgd_solver.cpp:106] Iteration 13400, lr = 5.28552e-05
I0321 21:58:50.974275  6540 solver.cpp:337] Iteration 13500, Testing net (#0)
I0321 21:58:51.637311  6540 solver.cpp:404]     Test net output #0: accuracy = 0.86842
I0321 21:58:51.637349  6540 solver.cpp:404]     Test net output #1: loss = 0.426641 (* 1 = 0.426641 loss)
I0321 21:58:51.770115  6540 solver.cpp:228] Iteration 13500, loss = 0.417686
I0321 21:58:51.770150  6540 solver.cpp:244]     Train net output #0: loss = 0.417686 (* 1 = 0.417686 loss)
I0321 21:58:51.770157  6540 sgd_solver.cpp:106] Iteration 13500, lr = 5.26865e-05
I0321 21:59:23.997741  6540 solver.cpp:228] Iteration 13600, loss = 0.399018
I0321 21:59:23.997805  6540 solver.cpp:244]     Train net output #0: loss = 0.399018 (* 1 = 0.399018 loss)
I0321 21:59:23.997813  6540 sgd_solver.cpp:106] Iteration 13600, lr = 5.25189e-05
I0321 21:59:56.226788  6540 solver.cpp:228] Iteration 13700, loss = 0.406646
I0321 21:59:56.226851  6540 solver.cpp:244]     Train net output #0: loss = 0.406646 (* 1 = 0.406646 loss)
I0321 21:59:56.226860  6540 sgd_solver.cpp:106] Iteration 13700, lr = 5.23527e-05
I0321 22:00:28.475498  6540 solver.cpp:228] Iteration 13800, loss = 0.416399
I0321 22:00:28.475591  6540 solver.cpp:244]     Train net output #0: loss = 0.416399 (* 1 = 0.416399 loss)
I0321 22:00:28.475599  6540 sgd_solver.cpp:106] Iteration 13800, lr = 5.21876e-05
I0321 22:01:00.770910  6540 solver.cpp:228] Iteration 13900, loss = 0.4157
I0321 22:01:00.770963  6540 solver.cpp:244]     Train net output #0: loss = 0.4157 (* 1 = 0.4157 loss)
I0321 22:01:00.770970  6540 sgd_solver.cpp:106] Iteration 13900, lr = 5.20237e-05
I0321 22:01:32.659322  6540 solver.cpp:337] Iteration 14000, Testing net (#0)
I0321 22:01:33.322419  6540 solver.cpp:404]     Test net output #0: accuracy = 0.86958
I0321 22:01:33.322454  6540 solver.cpp:404]     Test net output #1: loss = 0.423394 (* 1 = 0.423394 loss)
I0321 22:01:33.454943  6540 solver.cpp:228] Iteration 14000, loss = 0.395421
I0321 22:01:33.454979  6540 solver.cpp:244]     Train net output #0: loss = 0.395421 (* 1 = 0.395421 loss)
I0321 22:01:33.454987  6540 sgd_solver.cpp:106] Iteration 14000, lr = 5.18611e-05
I0321 22:02:05.678606  6540 solver.cpp:228] Iteration 14100, loss = 0.403332
I0321 22:02:05.678711  6540 solver.cpp:244]     Train net output #0: loss = 0.403332 (* 1 = 0.403332 loss)
I0321 22:02:05.678730  6540 sgd_solver.cpp:106] Iteration 14100, lr = 5.16996e-05
I0321 22:02:37.867105  6540 solver.cpp:228] Iteration 14200, loss = 0.413406
I0321 22:02:37.867203  6540 solver.cpp:244]     Train net output #0: loss = 0.413406 (* 1 = 0.413406 loss)
I0321 22:02:37.867211  6540 sgd_solver.cpp:106] Iteration 14200, lr = 5.15393e-05
I0321 22:03:10.074229  6540 solver.cpp:228] Iteration 14300, loss = 0.413216
I0321 22:03:10.074308  6540 solver.cpp:244]     Train net output #0: loss = 0.413216 (* 1 = 0.413216 loss)
I0321 22:03:10.074324  6540 sgd_solver.cpp:106] Iteration 14300, lr = 5.13801e-05
I0321 22:03:42.289516  6540 solver.cpp:228] Iteration 14400, loss = 0.395026
I0321 22:03:42.289618  6540 solver.cpp:244]     Train net output #0: loss = 0.395026 (* 1 = 0.395026 loss)
I0321 22:03:42.289624  6540 sgd_solver.cpp:106] Iteration 14400, lr = 5.12221e-05
I0321 22:04:14.155280  6540 solver.cpp:337] Iteration 14500, Testing net (#0)
I0321 22:04:14.815186  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87052
I0321 22:04:14.815223  6540 solver.cpp:404]     Test net output #1: loss = 0.420746 (* 1 = 0.420746 loss)
I0321 22:04:14.946965  6540 solver.cpp:228] Iteration 14500, loss = 0.402079
I0321 22:04:14.947001  6540 solver.cpp:244]     Train net output #0: loss = 0.402079 (* 1 = 0.402079 loss)
I0321 22:04:14.947007  6540 sgd_solver.cpp:106] Iteration 14500, lr = 5.10652e-05
I0321 22:04:47.199637  6540 solver.cpp:228] Iteration 14600, loss = 0.410921
I0321 22:04:47.199735  6540 solver.cpp:244]     Train net output #0: loss = 0.410921 (* 1 = 0.410921 loss)
I0321 22:04:47.199743  6540 sgd_solver.cpp:106] Iteration 14600, lr = 5.09095e-05
I0321 22:05:19.464495  6540 solver.cpp:228] Iteration 14700, loss = 0.410266
I0321 22:05:19.464578  6540 solver.cpp:244]     Train net output #0: loss = 0.410266 (* 1 = 0.410266 loss)
I0321 22:05:19.464594  6540 sgd_solver.cpp:106] Iteration 14700, lr = 5.07548e-05
I0321 22:05:51.683712  6540 solver.cpp:228] Iteration 14800, loss = 0.388997
I0321 22:05:51.683805  6540 solver.cpp:244]     Train net output #0: loss = 0.388997 (* 1 = 0.388997 loss)
I0321 22:05:51.683822  6540 sgd_solver.cpp:106] Iteration 14800, lr = 5.06012e-05
I0321 22:06:24.197211  6540 solver.cpp:228] Iteration 14900, loss = 0.400781
I0321 22:06:24.197264  6540 solver.cpp:244]     Train net output #0: loss = 0.400781 (* 1 = 0.400781 loss)
I0321 22:06:24.197271  6540 sgd_solver.cpp:106] Iteration 14900, lr = 5.04488e-05
I0321 22:06:56.064929  6540 solver.cpp:454] Snapshotting to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_15000.caffemodel
I0321 22:06:56.263075  6540 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_15000.solverstate
I0321 22:06:56.264822  6540 solver.cpp:337] Iteration 15000, Testing net (#0)
I0321 22:06:56.735514  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87118
I0321 22:06:56.735543  6540 solver.cpp:404]     Test net output #1: loss = 0.41904 (* 1 = 0.41904 loss)
I0321 22:06:56.868356  6540 solver.cpp:228] Iteration 15000, loss = 0.409184
I0321 22:06:56.868392  6540 solver.cpp:244]     Train net output #0: loss = 0.409184 (* 1 = 0.409184 loss)
I0321 22:06:56.868399  6540 sgd_solver.cpp:106] Iteration 15000, lr = 5.02973e-05
I0321 22:07:29.042387  6540 solver.cpp:228] Iteration 15100, loss = 0.407409
I0321 22:07:29.042508  6540 solver.cpp:244]     Train net output #0: loss = 0.407409 (* 1 = 0.407409 loss)
I0321 22:07:29.042517  6540 sgd_solver.cpp:106] Iteration 15100, lr = 5.0147e-05
I0321 22:08:01.315805  6540 solver.cpp:228] Iteration 15200, loss = 0.387303
I0321 22:08:01.315888  6540 solver.cpp:244]     Train net output #0: loss = 0.387303 (* 1 = 0.387303 loss)
I0321 22:08:01.315906  6540 sgd_solver.cpp:106] Iteration 15200, lr = 4.99976e-05
I0321 22:08:33.523428  6540 solver.cpp:228] Iteration 15300, loss = 0.398401
I0321 22:08:33.523510  6540 solver.cpp:244]     Train net output #0: loss = 0.398401 (* 1 = 0.398401 loss)
I0321 22:08:33.523526  6540 sgd_solver.cpp:106] Iteration 15300, lr = 4.98494e-05
I0321 22:09:05.858639  6540 solver.cpp:228] Iteration 15400, loss = 0.405677
I0321 22:09:05.858738  6540 solver.cpp:244]     Train net output #0: loss = 0.405677 (* 1 = 0.405677 loss)
I0321 22:09:05.858745  6540 sgd_solver.cpp:106] Iteration 15400, lr = 4.97021e-05
I0321 22:09:37.717304  6540 solver.cpp:337] Iteration 15500, Testing net (#0)
I0321 22:09:38.381196  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87244
I0321 22:09:38.381235  6540 solver.cpp:404]     Test net output #1: loss = 0.415266 (* 1 = 0.415266 loss)
I0321 22:09:38.513041  6540 solver.cpp:228] Iteration 15500, loss = 0.405699
I0321 22:09:38.513077  6540 solver.cpp:244]     Train net output #0: loss = 0.405699 (* 1 = 0.405699 loss)
I0321 22:09:38.513084  6540 sgd_solver.cpp:106] Iteration 15500, lr = 4.95558e-05
I0321 22:10:10.720870  6540 solver.cpp:228] Iteration 15600, loss = 0.388296
I0321 22:10:10.720939  6540 solver.cpp:244]     Train net output #0: loss = 0.388296 (* 1 = 0.388296 loss)
I0321 22:10:10.720947  6540 sgd_solver.cpp:106] Iteration 15600, lr = 4.94106e-05
I0321 22:10:42.961652  6540 solver.cpp:228] Iteration 15700, loss = 0.395705
I0321 22:10:42.961751  6540 solver.cpp:244]     Train net output #0: loss = 0.395705 (* 1 = 0.395705 loss)
I0321 22:10:42.961758  6540 sgd_solver.cpp:106] Iteration 15700, lr = 4.92663e-05
I0321 22:11:15.176749  6540 solver.cpp:228] Iteration 15800, loss = 0.404091
I0321 22:11:15.176820  6540 solver.cpp:244]     Train net output #0: loss = 0.404091 (* 1 = 0.404091 loss)
I0321 22:11:15.176826  6540 sgd_solver.cpp:106] Iteration 15800, lr = 4.9123e-05
I0321 22:11:47.400280  6540 solver.cpp:228] Iteration 15900, loss = 0.403621
I0321 22:11:47.400378  6540 solver.cpp:244]     Train net output #0: loss = 0.403621 (* 1 = 0.403621 loss)
I0321 22:11:47.400385  6540 sgd_solver.cpp:106] Iteration 15900, lr = 4.89807e-05
I0321 22:12:19.304785  6540 solver.cpp:337] Iteration 16000, Testing net (#0)
I0321 22:12:19.967633  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87242
I0321 22:12:19.967671  6540 solver.cpp:404]     Test net output #1: loss = 0.413896 (* 1 = 0.413896 loss)
I0321 22:12:20.100471  6540 solver.cpp:228] Iteration 16000, loss = 0.384916
I0321 22:12:20.100505  6540 solver.cpp:244]     Train net output #0: loss = 0.384916 (* 1 = 0.384916 loss)
I0321 22:12:20.100513  6540 sgd_solver.cpp:106] Iteration 16000, lr = 4.88394e-05
I0321 22:12:52.423569  6540 solver.cpp:228] Iteration 16100, loss = 0.395034
I0321 22:12:52.423671  6540 solver.cpp:244]     Train net output #0: loss = 0.395034 (* 1 = 0.395034 loss)
I0321 22:12:52.423679  6540 sgd_solver.cpp:106] Iteration 16100, lr = 4.86989e-05
I0321 22:13:24.340507  6540 solver.cpp:228] Iteration 16200, loss = 0.402513
I0321 22:13:24.340572  6540 solver.cpp:244]     Train net output #0: loss = 0.402513 (* 1 = 0.402513 loss)
I0321 22:13:24.340580  6540 sgd_solver.cpp:106] Iteration 16200, lr = 4.85595e-05
I0321 22:13:56.447235  6540 solver.cpp:228] Iteration 16300, loss = 0.404915
I0321 22:13:56.447309  6540 solver.cpp:244]     Train net output #0: loss = 0.404915 (* 1 = 0.404915 loss)
I0321 22:13:56.447319  6540 sgd_solver.cpp:106] Iteration 16300, lr = 4.84209e-05
I0321 22:14:28.311735  6540 solver.cpp:228] Iteration 16400, loss = 0.382047
I0321 22:14:28.311801  6540 solver.cpp:244]     Train net output #0: loss = 0.382047 (* 1 = 0.382047 loss)
I0321 22:14:28.311810  6540 sgd_solver.cpp:106] Iteration 16400, lr = 4.82833e-05
I0321 22:14:59.826632  6540 solver.cpp:337] Iteration 16500, Testing net (#0)
I0321 22:15:00.503731  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87342
I0321 22:15:00.503769  6540 solver.cpp:404]     Test net output #1: loss = 0.411472 (* 1 = 0.411472 loss)
I0321 22:15:00.636525  6540 solver.cpp:228] Iteration 16500, loss = 0.39208
I0321 22:15:00.636559  6540 solver.cpp:244]     Train net output #0: loss = 0.39208 (* 1 = 0.39208 loss)
I0321 22:15:00.636566  6540 sgd_solver.cpp:106] Iteration 16500, lr = 4.81466e-05
I0321 22:15:32.883209  6540 solver.cpp:228] Iteration 16600, loss = 0.399726
I0321 22:15:32.883294  6540 solver.cpp:244]     Train net output #0: loss = 0.399726 (* 1 = 0.399726 loss)
I0321 22:15:32.883311  6540 sgd_solver.cpp:106] Iteration 16600, lr = 4.80108e-05
I0321 22:16:05.159060  6540 solver.cpp:228] Iteration 16700, loss = 0.404066
I0321 22:16:05.159157  6540 solver.cpp:244]     Train net output #0: loss = 0.404066 (* 1 = 0.404066 loss)
I0321 22:16:05.159164  6540 sgd_solver.cpp:106] Iteration 16700, lr = 4.78759e-05
I0321 22:16:37.399991  6540 solver.cpp:228] Iteration 16800, loss = 0.379883
I0321 22:16:37.400048  6540 solver.cpp:244]     Train net output #0: loss = 0.379883 (* 1 = 0.379883 loss)
I0321 22:16:37.400055  6540 sgd_solver.cpp:106] Iteration 16800, lr = 4.77418e-05
I0321 22:17:09.584316  6540 solver.cpp:228] Iteration 16900, loss = 0.390648
I0321 22:17:09.584385  6540 solver.cpp:244]     Train net output #0: loss = 0.390648 (* 1 = 0.390648 loss)
I0321 22:17:09.584393  6540 sgd_solver.cpp:106] Iteration 16900, lr = 4.76086e-05
I0321 22:17:41.417449  6540 solver.cpp:337] Iteration 17000, Testing net (#0)
I0321 22:17:42.089679  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87396
I0321 22:17:42.089716  6540 solver.cpp:404]     Test net output #1: loss = 0.409784 (* 1 = 0.409784 loss)
I0321 22:17:42.221503  6540 solver.cpp:228] Iteration 17000, loss = 0.395717
I0321 22:17:42.221539  6540 solver.cpp:244]     Train net output #0: loss = 0.395717 (* 1 = 0.395717 loss)
I0321 22:17:42.221545  6540 sgd_solver.cpp:106] Iteration 17000, lr = 4.74763e-05
I0321 22:18:14.458281  6540 solver.cpp:228] Iteration 17100, loss = 0.400554
I0321 22:18:14.458345  6540 solver.cpp:244]     Train net output #0: loss = 0.400554 (* 1 = 0.400554 loss)
I0321 22:18:14.458353  6540 sgd_solver.cpp:106] Iteration 17100, lr = 4.73449e-05
I0321 22:18:46.608953  6540 solver.cpp:228] Iteration 17200, loss = 0.378613
I0321 22:18:46.609017  6540 solver.cpp:244]     Train net output #0: loss = 0.378613 (* 1 = 0.378613 loss)
I0321 22:18:46.609027  6540 sgd_solver.cpp:106] Iteration 17200, lr = 4.72143e-05
I0321 22:19:18.683214  6540 solver.cpp:228] Iteration 17300, loss = 0.38884
I0321 22:19:18.683300  6540 solver.cpp:244]     Train net output #0: loss = 0.38884 (* 1 = 0.38884 loss)
I0321 22:19:18.683317  6540 sgd_solver.cpp:106] Iteration 17300, lr = 4.70845e-05
I0321 22:19:50.557487  6540 solver.cpp:228] Iteration 17400, loss = 0.394257
I0321 22:19:50.559209  6540 solver.cpp:244]     Train net output #0: loss = 0.394257 (* 1 = 0.394257 loss)
I0321 22:19:50.559231  6540 sgd_solver.cpp:106] Iteration 17400, lr = 4.69556e-05
I0321 22:20:22.188807  6540 solver.cpp:337] Iteration 17500, Testing net (#0)
I0321 22:20:22.879526  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87482
I0321 22:20:22.879565  6540 solver.cpp:404]     Test net output #1: loss = 0.407191 (* 1 = 0.407191 loss)
I0321 22:20:23.012631  6540 solver.cpp:228] Iteration 17500, loss = 0.399042
I0321 22:20:23.012655  6540 solver.cpp:244]     Train net output #0: loss = 0.399042 (* 1 = 0.399042 loss)
I0321 22:20:23.012662  6540 sgd_solver.cpp:106] Iteration 17500, lr = 4.68274e-05
I0321 22:20:55.256839  6540 solver.cpp:228] Iteration 17600, loss = 0.379192
I0321 22:20:55.256922  6540 solver.cpp:244]     Train net output #0: loss = 0.379192 (* 1 = 0.379192 loss)
I0321 22:20:55.256937  6540 sgd_solver.cpp:106] Iteration 17600, lr = 4.67001e-05
I0321 22:21:27.471782  6540 solver.cpp:228] Iteration 17700, loss = 0.384639
I0321 22:21:27.471859  6540 solver.cpp:244]     Train net output #0: loss = 0.384639 (* 1 = 0.384639 loss)
I0321 22:21:27.471868  6540 sgd_solver.cpp:106] Iteration 17700, lr = 4.65736e-05
I0321 22:21:59.693389  6540 solver.cpp:228] Iteration 17800, loss = 0.390595
I0321 22:21:59.693490  6540 solver.cpp:244]     Train net output #0: loss = 0.390595 (* 1 = 0.390595 loss)
I0321 22:21:59.693497  6540 sgd_solver.cpp:106] Iteration 17800, lr = 4.64479e-05
I0321 22:22:31.983229  6540 solver.cpp:228] Iteration 17900, loss = 0.397767
I0321 22:22:31.983314  6540 solver.cpp:244]     Train net output #0: loss = 0.397767 (* 1 = 0.397767 loss)
I0321 22:22:31.983330  6540 sgd_solver.cpp:106] Iteration 17900, lr = 4.6323e-05
I0321 22:23:03.911723  6540 solver.cpp:337] Iteration 18000, Testing net (#0)
I0321 22:23:04.570629  6540 solver.cpp:404]     Test net output #0: accuracy = 0.8756
I0321 22:23:04.570665  6540 solver.cpp:404]     Test net output #1: loss = 0.405188 (* 1 = 0.405188 loss)
I0321 22:23:04.703670  6540 solver.cpp:228] Iteration 18000, loss = 0.379512
I0321 22:23:04.703707  6540 solver.cpp:244]     Train net output #0: loss = 0.379512 (* 1 = 0.379512 loss)
I0321 22:23:04.703714  6540 sgd_solver.cpp:106] Iteration 18000, lr = 4.61989e-05
I0321 22:23:37.027449  6540 solver.cpp:228] Iteration 18100, loss = 0.384152
I0321 22:23:37.027516  6540 solver.cpp:244]     Train net output #0: loss = 0.384152 (* 1 = 0.384152 loss)
I0321 22:23:37.027524  6540 sgd_solver.cpp:106] Iteration 18100, lr = 4.60755e-05
I0321 22:24:09.334826  6540 solver.cpp:228] Iteration 18200, loss = 0.388292
I0321 22:24:09.334908  6540 solver.cpp:244]     Train net output #0: loss = 0.388292 (* 1 = 0.388292 loss)
I0321 22:24:09.334924  6540 sgd_solver.cpp:106] Iteration 18200, lr = 4.59529e-05
I0321 22:24:41.622426  6540 solver.cpp:228] Iteration 18300, loss = 0.396024
I0321 22:24:41.622495  6540 solver.cpp:244]     Train net output #0: loss = 0.396024 (* 1 = 0.396024 loss)
I0321 22:24:41.622503  6540 sgd_solver.cpp:106] Iteration 18300, lr = 4.58311e-05
I0321 22:25:13.843163  6540 solver.cpp:228] Iteration 18400, loss = 0.37904
I0321 22:25:13.843243  6540 solver.cpp:244]     Train net output #0: loss = 0.37904 (* 1 = 0.37904 loss)
I0321 22:25:13.843260  6540 sgd_solver.cpp:106] Iteration 18400, lr = 4.571e-05
I0321 22:25:45.762476  6540 solver.cpp:337] Iteration 18500, Testing net (#0)
I0321 22:25:46.424772  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87602
I0321 22:25:46.424808  6540 solver.cpp:404]     Test net output #1: loss = 0.403629 (* 1 = 0.403629 loss)
I0321 22:25:46.557574  6540 solver.cpp:228] Iteration 18500, loss = 0.381428
I0321 22:25:46.557610  6540 solver.cpp:244]     Train net output #0: loss = 0.381428 (* 1 = 0.381428 loss)
I0321 22:25:46.557616  6540 sgd_solver.cpp:106] Iteration 18500, lr = 4.55897e-05
I0321 22:26:18.780308  6540 solver.cpp:228] Iteration 18600, loss = 0.390366
I0321 22:26:18.780405  6540 solver.cpp:244]     Train net output #0: loss = 0.390366 (* 1 = 0.390366 loss)
I0321 22:26:18.780413  6540 sgd_solver.cpp:106] Iteration 18600, lr = 4.54701e-05
I0321 22:26:51.066149  6540 solver.cpp:228] Iteration 18700, loss = 0.394197
I0321 22:26:51.066258  6540 solver.cpp:244]     Train net output #0: loss = 0.394197 (* 1 = 0.394197 loss)
I0321 22:26:51.066275  6540 sgd_solver.cpp:106] Iteration 18700, lr = 4.53512e-05
I0321 22:27:23.360657  6540 solver.cpp:228] Iteration 18800, loss = 0.378581
I0321 22:27:23.360728  6540 solver.cpp:244]     Train net output #0: loss = 0.378581 (* 1 = 0.378581 loss)
I0321 22:27:23.360735  6540 sgd_solver.cpp:106] Iteration 18800, lr = 4.5233e-05
I0321 22:27:55.546931  6540 solver.cpp:228] Iteration 18900, loss = 0.380731
I0321 22:27:55.547019  6540 solver.cpp:244]     Train net output #0: loss = 0.380731 (* 1 = 0.380731 loss)
I0321 22:27:55.547035  6540 sgd_solver.cpp:106] Iteration 18900, lr = 4.51156e-05
I0321 22:28:27.553563  6540 solver.cpp:337] Iteration 19000, Testing net (#0)
I0321 22:28:28.217322  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87676
I0321 22:28:28.217348  6540 solver.cpp:404]     Test net output #1: loss = 0.401572 (* 1 = 0.401572 loss)
I0321 22:28:28.350303  6540 solver.cpp:228] Iteration 19000, loss = 0.388966
I0321 22:28:28.350338  6540 solver.cpp:244]     Train net output #0: loss = 0.388966 (* 1 = 0.388966 loss)
I0321 22:28:28.350345  6540 sgd_solver.cpp:106] Iteration 19000, lr = 4.49989e-05
I0321 22:29:00.566267  6540 solver.cpp:228] Iteration 19100, loss = 0.393544
I0321 22:29:00.566365  6540 solver.cpp:244]     Train net output #0: loss = 0.393544 (* 1 = 0.393544 loss)
I0321 22:29:00.566382  6540 sgd_solver.cpp:106] Iteration 19100, lr = 4.48828e-05
I0321 22:29:32.775532  6540 solver.cpp:228] Iteration 19200, loss = 0.378951
I0321 22:29:32.775660  6540 solver.cpp:244]     Train net output #0: loss = 0.378951 (* 1 = 0.378951 loss)
I0321 22:29:32.775676  6540 sgd_solver.cpp:106] Iteration 19200, lr = 4.47675e-05
I0321 22:30:05.039600  6540 solver.cpp:228] Iteration 19300, loss = 0.381416
I0321 22:30:05.039700  6540 solver.cpp:244]     Train net output #0: loss = 0.381416 (* 1 = 0.381416 loss)
I0321 22:30:05.039708  6540 sgd_solver.cpp:106] Iteration 19300, lr = 4.46529e-05
I0321 22:30:37.311748  6540 solver.cpp:228] Iteration 19400, loss = 0.387468
I0321 22:30:37.311844  6540 solver.cpp:244]     Train net output #0: loss = 0.387468 (* 1 = 0.387468 loss)
I0321 22:30:37.311851  6540 sgd_solver.cpp:106] Iteration 19400, lr = 4.45389e-05
I0321 22:31:09.173161  6540 solver.cpp:337] Iteration 19500, Testing net (#0)
I0321 22:31:09.837571  6540 solver.cpp:404]     Test net output #0: accuracy = 0.8773
I0321 22:31:09.837610  6540 solver.cpp:404]     Test net output #1: loss = 0.400352 (* 1 = 0.400352 loss)
I0321 22:31:09.969640  6540 solver.cpp:228] Iteration 19500, loss = 0.390638
I0321 22:31:09.969674  6540 solver.cpp:244]     Train net output #0: loss = 0.390638 (* 1 = 0.390638 loss)
I0321 22:31:09.969681  6540 sgd_solver.cpp:106] Iteration 19500, lr = 4.44256e-05
I0321 22:31:42.208048  6540 solver.cpp:228] Iteration 19600, loss = 0.376726
I0321 22:31:42.208132  6540 solver.cpp:244]     Train net output #0: loss = 0.376726 (* 1 = 0.376726 loss)
I0321 22:31:42.208148  6540 sgd_solver.cpp:106] Iteration 19600, lr = 4.4313e-05
I0321 22:32:14.388485  6540 solver.cpp:228] Iteration 19700, loss = 0.379126
I0321 22:32:14.388546  6540 solver.cpp:244]     Train net output #0: loss = 0.379126 (* 1 = 0.379126 loss)
I0321 22:32:14.388553  6540 sgd_solver.cpp:106] Iteration 19700, lr = 4.42011e-05
I0321 22:32:46.673894  6540 solver.cpp:228] Iteration 19800, loss = 0.385561
I0321 22:32:46.673995  6540 solver.cpp:244]     Train net output #0: loss = 0.385561 (* 1 = 0.385561 loss)
I0321 22:32:46.674001  6540 sgd_solver.cpp:106] Iteration 19800, lr = 4.40898e-05
I0321 22:33:19.009769  6540 solver.cpp:228] Iteration 19900, loss = 0.38761
I0321 22:33:19.009840  6540 solver.cpp:244]     Train net output #0: loss = 0.38761 (* 1 = 0.38761 loss)
I0321 22:33:19.009847  6540 sgd_solver.cpp:106] Iteration 19900, lr = 4.39791e-05
I0321 22:33:50.928020  6540 solver.cpp:454] Snapshotting to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_20000.caffemodel
I0321 22:33:51.129544  6540 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_20000.solverstate
I0321 22:33:51.131314  6540 solver.cpp:337] Iteration 20000, Testing net (#0)
I0321 22:33:51.599241  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87798
I0321 22:33:51.599277  6540 solver.cpp:404]     Test net output #1: loss = 0.3975 (* 1 = 0.3975 loss)
I0321 22:33:51.732255  6540 solver.cpp:228] Iteration 20000, loss = 0.376374
I0321 22:33:51.732281  6540 solver.cpp:244]     Train net output #0: loss = 0.376374 (* 1 = 0.376374 loss)
I0321 22:33:51.732288  6540 sgd_solver.cpp:106] Iteration 20000, lr = 4.38691e-05
I0321 22:34:23.967816  6540 solver.cpp:228] Iteration 20100, loss = 0.374118
I0321 22:34:23.967883  6540 solver.cpp:244]     Train net output #0: loss = 0.374118 (* 1 = 0.374118 loss)
I0321 22:34:23.967890  6540 sgd_solver.cpp:106] Iteration 20100, lr = 4.37598e-05
I0321 22:34:56.223299  6540 solver.cpp:228] Iteration 20200, loss = 0.385635
I0321 22:34:56.223422  6540 solver.cpp:244]     Train net output #0: loss = 0.385635 (* 1 = 0.385635 loss)
I0321 22:34:56.223439  6540 sgd_solver.cpp:106] Iteration 20200, lr = 4.36511e-05
I0321 22:35:28.484791  6540 solver.cpp:228] Iteration 20300, loss = 0.38726
I0321 22:35:28.484894  6540 solver.cpp:244]     Train net output #0: loss = 0.38726 (* 1 = 0.38726 loss)
I0321 22:35:28.484901  6540 sgd_solver.cpp:106] Iteration 20300, lr = 4.3543e-05
I0321 22:36:00.712146  6540 solver.cpp:228] Iteration 20400, loss = 0.377094
I0321 22:36:00.712232  6540 solver.cpp:244]     Train net output #0: loss = 0.377094 (* 1 = 0.377094 loss)
I0321 22:36:00.712249  6540 sgd_solver.cpp:106] Iteration 20400, lr = 4.34355e-05
I0321 22:36:32.638509  6540 solver.cpp:337] Iteration 20500, Testing net (#0)
I0321 22:36:33.303426  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87826
I0321 22:36:33.303452  6540 solver.cpp:404]     Test net output #1: loss = 0.396658 (* 1 = 0.396658 loss)
I0321 22:36:33.435969  6540 solver.cpp:228] Iteration 20500, loss = 0.373013
I0321 22:36:33.436008  6540 solver.cpp:244]     Train net output #0: loss = 0.373013 (* 1 = 0.373013 loss)
I0321 22:36:33.436015  6540 sgd_solver.cpp:106] Iteration 20500, lr = 4.33286e-05
I0321 22:37:06.027467  6540 solver.cpp:228] Iteration 20600, loss = 0.382877
I0321 22:37:06.027570  6540 solver.cpp:244]     Train net output #0: loss = 0.382877 (* 1 = 0.382877 loss)
I0321 22:37:06.027577  6540 sgd_solver.cpp:106] Iteration 20600, lr = 4.32224e-05
I0321 22:37:38.305714  6540 solver.cpp:228] Iteration 20700, loss = 0.3873
I0321 22:37:38.305814  6540 solver.cpp:244]     Train net output #0: loss = 0.3873 (* 1 = 0.3873 loss)
I0321 22:37:38.305820  6540 sgd_solver.cpp:106] Iteration 20700, lr = 4.31168e-05
I0321 22:38:10.559564  6540 solver.cpp:228] Iteration 20800, loss = 0.37577
I0321 22:38:10.559649  6540 solver.cpp:244]     Train net output #0: loss = 0.37577 (* 1 = 0.37577 loss)
I0321 22:38:10.559666  6540 sgd_solver.cpp:106] Iteration 20800, lr = 4.30117e-05
I0321 22:38:42.871717  6540 solver.cpp:228] Iteration 20900, loss = 0.372523
I0321 22:38:42.871798  6540 solver.cpp:244]     Train net output #0: loss = 0.372523 (* 1 = 0.372523 loss)
I0321 22:38:42.871806  6540 sgd_solver.cpp:106] Iteration 20900, lr = 4.29073e-05
I0321 22:39:14.751689  6540 solver.cpp:337] Iteration 21000, Testing net (#0)
I0321 22:39:15.414069  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87852
I0321 22:39:15.414108  6540 solver.cpp:404]     Test net output #1: loss = 0.395484 (* 1 = 0.395484 loss)
I0321 22:39:15.547066  6540 solver.cpp:228] Iteration 21000, loss = 0.378837
I0321 22:39:15.547102  6540 solver.cpp:244]     Train net output #0: loss = 0.378837 (* 1 = 0.378837 loss)
I0321 22:39:15.547109  6540 sgd_solver.cpp:106] Iteration 21000, lr = 4.28034e-05
I0321 22:39:47.827754  6540 solver.cpp:228] Iteration 21100, loss = 0.386772
I0321 22:39:47.827853  6540 solver.cpp:244]     Train net output #0: loss = 0.386772 (* 1 = 0.386772 loss)
I0321 22:39:47.827862  6540 sgd_solver.cpp:106] Iteration 21100, lr = 4.27002e-05
I0321 22:40:20.129724  6540 solver.cpp:228] Iteration 21200, loss = 0.37406
I0321 22:40:20.129823  6540 solver.cpp:244]     Train net output #0: loss = 0.37406 (* 1 = 0.37406 loss)
I0321 22:40:20.129832  6540 sgd_solver.cpp:106] Iteration 21200, lr = 4.25975e-05
I0321 22:40:52.383343  6540 solver.cpp:228] Iteration 21300, loss = 0.368962
I0321 22:40:52.383422  6540 solver.cpp:244]     Train net output #0: loss = 0.368962 (* 1 = 0.368962 loss)
I0321 22:40:52.383440  6540 sgd_solver.cpp:106] Iteration 21300, lr = 4.24954e-05
I0321 22:41:24.597285  6540 solver.cpp:228] Iteration 21400, loss = 0.379068
I0321 22:41:24.597355  6540 solver.cpp:244]     Train net output #0: loss = 0.379068 (* 1 = 0.379068 loss)
I0321 22:41:24.597363  6540 sgd_solver.cpp:106] Iteration 21400, lr = 4.23938e-05
I0321 22:41:56.568706  6540 solver.cpp:337] Iteration 21500, Testing net (#0)
I0321 22:41:57.232190  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87918
I0321 22:41:57.232228  6540 solver.cpp:404]     Test net output #1: loss = 0.393061 (* 1 = 0.393061 loss)
I0321 22:41:57.364711  6540 solver.cpp:228] Iteration 21500, loss = 0.386317
I0321 22:41:57.364745  6540 solver.cpp:244]     Train net output #0: loss = 0.386317 (* 1 = 0.386317 loss)
I0321 22:41:57.364753  6540 sgd_solver.cpp:106] Iteration 21500, lr = 4.22929e-05
I0321 22:42:29.594339  6540 solver.cpp:228] Iteration 21600, loss = 0.372969
I0321 22:42:29.594446  6540 solver.cpp:244]     Train net output #0: loss = 0.372969 (* 1 = 0.372969 loss)
I0321 22:42:29.594455  6540 sgd_solver.cpp:106] Iteration 21600, lr = 4.21924e-05
I0321 22:43:01.862505  6540 solver.cpp:228] Iteration 21700, loss = 0.364734
I0321 22:43:01.862578  6540 solver.cpp:244]     Train net output #0: loss = 0.364734 (* 1 = 0.364734 loss)
I0321 22:43:01.862586  6540 sgd_solver.cpp:106] Iteration 21700, lr = 4.20926e-05
I0321 22:43:34.132843  6540 solver.cpp:228] Iteration 21800, loss = 0.378512
I0321 22:43:34.132925  6540 solver.cpp:244]     Train net output #0: loss = 0.378512 (* 1 = 0.378512 loss)
I0321 22:43:34.132941  6540 sgd_solver.cpp:106] Iteration 21800, lr = 4.19933e-05
I0321 22:44:06.315701  6540 solver.cpp:228] Iteration 21900, loss = 0.381135
I0321 22:44:06.315778  6540 solver.cpp:244]     Train net output #0: loss = 0.381135 (* 1 = 0.381135 loss)
I0321 22:44:06.315793  6540 sgd_solver.cpp:106] Iteration 21900, lr = 4.18945e-05
I0321 22:44:38.256106  6540 solver.cpp:337] Iteration 22000, Testing net (#0)
I0321 22:44:38.916570  6540 solver.cpp:404]     Test net output #0: accuracy = 0.87946
I0321 22:44:38.916609  6540 solver.cpp:404]     Test net output #1: loss = 0.392123 (* 1 = 0.392123 loss)
I0321 22:44:39.047915  6540 solver.cpp:228] Iteration 22000, loss = 0.373369
I0321 22:44:39.047952  6540 solver.cpp:244]     Train net output #0: loss = 0.373369 (* 1 = 0.373369 loss)
I0321 22:44:39.047960  6540 sgd_solver.cpp:106] Iteration 22000, lr = 4.17963e-05
I0321 22:45:11.270637  6540 solver.cpp:228] Iteration 22100, loss = 0.362648
I0321 22:45:11.270717  6540 solver.cpp:244]     Train net output #0: loss = 0.362648 (* 1 = 0.362648 loss)
I0321 22:45:11.270725  6540 sgd_solver.cpp:106] Iteration 22100, lr = 4.16986e-05
I0321 22:45:43.449190  6540 solver.cpp:228] Iteration 22200, loss = 0.377995
I0321 22:45:43.449254  6540 solver.cpp:244]     Train net output #0: loss = 0.377995 (* 1 = 0.377995 loss)
I0321 22:45:43.449262  6540 sgd_solver.cpp:106] Iteration 22200, lr = 4.16014e-05
I0321 22:46:15.668866  6540 solver.cpp:228] Iteration 22300, loss = 0.379503
I0321 22:46:15.668920  6540 solver.cpp:244]     Train net output #0: loss = 0.379503 (* 1 = 0.379503 loss)
I0321 22:46:15.668926  6540 sgd_solver.cpp:106] Iteration 22300, lr = 4.15048e-05
I0321 22:46:47.922030  6540 solver.cpp:228] Iteration 22400, loss = 0.37114
I0321 22:46:47.922118  6540 solver.cpp:244]     Train net output #0: loss = 0.37114 (* 1 = 0.37114 loss)
I0321 22:46:47.922127  6540 sgd_solver.cpp:106] Iteration 22400, lr = 4.14087e-05
I0321 22:47:19.826033  6540 solver.cpp:337] Iteration 22500, Testing net (#0)
I0321 22:47:20.493360  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88004
I0321 22:47:20.493399  6540 solver.cpp:404]     Test net output #1: loss = 0.391035 (* 1 = 0.391035 loss)
I0321 22:47:20.625108  6540 solver.cpp:228] Iteration 22500, loss = 0.360571
I0321 22:47:20.625146  6540 solver.cpp:244]     Train net output #0: loss = 0.360571 (* 1 = 0.360571 loss)
I0321 22:47:20.625154  6540 sgd_solver.cpp:106] Iteration 22500, lr = 4.13131e-05
I0321 22:47:52.912173  6540 solver.cpp:228] Iteration 22600, loss = 0.375551
I0321 22:47:52.912225  6540 solver.cpp:244]     Train net output #0: loss = 0.375551 (* 1 = 0.375551 loss)
I0321 22:47:52.912233  6540 sgd_solver.cpp:106] Iteration 22600, lr = 4.1218e-05
I0321 22:48:25.200132  6540 solver.cpp:228] Iteration 22700, loss = 0.379678
I0321 22:48:25.200219  6540 solver.cpp:244]     Train net output #0: loss = 0.379678 (* 1 = 0.379678 loss)
I0321 22:48:25.200228  6540 sgd_solver.cpp:106] Iteration 22700, lr = 4.11234e-05
I0321 22:48:57.481106  6540 solver.cpp:228] Iteration 22800, loss = 0.374158
I0321 22:48:57.481164  6540 solver.cpp:244]     Train net output #0: loss = 0.374158 (* 1 = 0.374158 loss)
I0321 22:48:57.481173  6540 sgd_solver.cpp:106] Iteration 22800, lr = 4.10293e-05
I0321 22:49:29.743710  6540 solver.cpp:228] Iteration 22900, loss = 0.358458
I0321 22:49:29.743778  6540 solver.cpp:244]     Train net output #0: loss = 0.358458 (* 1 = 0.358458 loss)
I0321 22:49:29.743787  6540 sgd_solver.cpp:106] Iteration 22900, lr = 4.09358e-05
I0321 22:50:01.703505  6540 solver.cpp:337] Iteration 23000, Testing net (#0)
I0321 22:50:02.361176  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88068
I0321 22:50:02.361201  6540 solver.cpp:404]     Test net output #1: loss = 0.389832 (* 1 = 0.389832 loss)
I0321 22:50:02.493703  6540 solver.cpp:228] Iteration 23000, loss = 0.373244
I0321 22:50:02.493728  6540 solver.cpp:244]     Train net output #0: loss = 0.373244 (* 1 = 0.373244 loss)
I0321 22:50:02.493736  6540 sgd_solver.cpp:106] Iteration 23000, lr = 4.08427e-05
I0321 22:50:34.754820  6540 solver.cpp:228] Iteration 23100, loss = 0.377787
I0321 22:50:34.754905  6540 solver.cpp:244]     Train net output #0: loss = 0.377787 (* 1 = 0.377787 loss)
I0321 22:50:34.754914  6540 sgd_solver.cpp:106] Iteration 23100, lr = 4.07501e-05
I0321 22:51:06.960083  6540 solver.cpp:228] Iteration 23200, loss = 0.374816
I0321 22:51:06.960160  6540 solver.cpp:244]     Train net output #0: loss = 0.374816 (* 1 = 0.374816 loss)
I0321 22:51:06.960168  6540 sgd_solver.cpp:106] Iteration 23200, lr = 4.0658e-05
I0321 22:51:39.270810  6540 solver.cpp:228] Iteration 23300, loss = 0.355417
I0321 22:51:39.270889  6540 solver.cpp:244]     Train net output #0: loss = 0.355417 (* 1 = 0.355417 loss)
I0321 22:51:39.270905  6540 sgd_solver.cpp:106] Iteration 23300, lr = 4.05664e-05
I0321 22:52:11.513453  6540 solver.cpp:228] Iteration 23400, loss = 0.372027
I0321 22:52:11.513519  6540 solver.cpp:244]     Train net output #0: loss = 0.372027 (* 1 = 0.372027 loss)
I0321 22:52:11.513526  6540 sgd_solver.cpp:106] Iteration 23400, lr = 4.04753e-05
I0321 22:52:43.464442  6540 solver.cpp:337] Iteration 23500, Testing net (#0)
I0321 22:52:44.129809  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88128
I0321 22:52:44.129838  6540 solver.cpp:404]     Test net output #1: loss = 0.388228 (* 1 = 0.388228 loss)
I0321 22:52:44.262943  6540 solver.cpp:228] Iteration 23500, loss = 0.374945
I0321 22:52:44.262977  6540 solver.cpp:244]     Train net output #0: loss = 0.374945 (* 1 = 0.374945 loss)
I0321 22:52:44.262984  6540 sgd_solver.cpp:106] Iteration 23500, lr = 4.03847e-05
I0321 22:53:16.495472  6540 solver.cpp:228] Iteration 23600, loss = 0.37505
I0321 22:53:16.495555  6540 solver.cpp:244]     Train net output #0: loss = 0.37505 (* 1 = 0.37505 loss)
I0321 22:53:16.495573  6540 sgd_solver.cpp:106] Iteration 23600, lr = 4.02945e-05
I0321 22:53:48.786803  6540 solver.cpp:228] Iteration 23700, loss = 0.35408
I0321 22:53:48.786872  6540 solver.cpp:244]     Train net output #0: loss = 0.35408 (* 1 = 0.35408 loss)
I0321 22:53:48.786880  6540 sgd_solver.cpp:106] Iteration 23700, lr = 4.02048e-05
I0321 22:54:21.044296  6540 solver.cpp:228] Iteration 23800, loss = 0.372054
I0321 22:54:21.044395  6540 solver.cpp:244]     Train net output #0: loss = 0.372054 (* 1 = 0.372054 loss)
I0321 22:54:21.044402  6540 sgd_solver.cpp:106] Iteration 23800, lr = 4.01155e-05
I0321 22:54:53.317509  6540 solver.cpp:228] Iteration 23900, loss = 0.374332
I0321 22:54:53.317595  6540 solver.cpp:244]     Train net output #0: loss = 0.374332 (* 1 = 0.374332 loss)
I0321 22:54:53.317603  6540 sgd_solver.cpp:106] Iteration 23900, lr = 4.00267e-05
I0321 22:55:25.228374  6540 solver.cpp:337] Iteration 24000, Testing net (#0)
I0321 22:55:25.887476  6540 solver.cpp:404]     Test net output #0: accuracy = 0.8816
I0321 22:55:25.887514  6540 solver.cpp:404]     Test net output #1: loss = 0.386704 (* 1 = 0.386704 loss)
I0321 22:55:26.019405  6540 solver.cpp:228] Iteration 24000, loss = 0.375294
I0321 22:55:26.019441  6540 solver.cpp:244]     Train net output #0: loss = 0.375294 (* 1 = 0.375294 loss)
I0321 22:55:26.019448  6540 sgd_solver.cpp:106] Iteration 24000, lr = 3.99384e-05
I0321 22:55:58.242142  6540 solver.cpp:228] Iteration 24100, loss = 0.353225
I0321 22:55:58.243191  6540 solver.cpp:244]     Train net output #0: loss = 0.353225 (* 1 = 0.353225 loss)
I0321 22:55:58.243209  6540 sgd_solver.cpp:106] Iteration 24100, lr = 3.98505e-05
I0321 22:56:30.445873  6540 solver.cpp:228] Iteration 24200, loss = 0.367731
I0321 22:56:30.445961  6540 solver.cpp:244]     Train net output #0: loss = 0.367731 (* 1 = 0.367731 loss)
I0321 22:56:30.445981  6540 sgd_solver.cpp:106] Iteration 24200, lr = 3.97631e-05
I0321 22:57:02.705507  6540 solver.cpp:228] Iteration 24300, loss = 0.373746
I0321 22:57:02.705580  6540 solver.cpp:244]     Train net output #0: loss = 0.373746 (* 1 = 0.373746 loss)
I0321 22:57:02.705587  6540 sgd_solver.cpp:106] Iteration 24300, lr = 3.96761e-05
I0321 22:57:34.962994  6540 solver.cpp:228] Iteration 24400, loss = 0.373304
I0321 22:57:34.963073  6540 solver.cpp:244]     Train net output #0: loss = 0.373304 (* 1 = 0.373304 loss)
I0321 22:57:34.963089  6540 sgd_solver.cpp:106] Iteration 24400, lr = 3.95896e-05
I0321 22:58:06.880085  6540 solver.cpp:337] Iteration 24500, Testing net (#0)
I0321 22:58:07.551775  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88218
I0321 22:58:07.551812  6540 solver.cpp:404]     Test net output #1: loss = 0.385006 (* 1 = 0.385006 loss)
I0321 22:58:07.683926  6540 solver.cpp:228] Iteration 24500, loss = 0.353195
I0321 22:58:07.683961  6540 solver.cpp:244]     Train net output #0: loss = 0.353195 (* 1 = 0.353195 loss)
I0321 22:58:07.683969  6540 sgd_solver.cpp:106] Iteration 24500, lr = 3.95035e-05
I0321 22:58:39.939673  6540 solver.cpp:228] Iteration 24600, loss = 0.367669
I0321 22:58:39.939770  6540 solver.cpp:244]     Train net output #0: loss = 0.367669 (* 1 = 0.367669 loss)
I0321 22:58:39.939779  6540 sgd_solver.cpp:106] Iteration 24600, lr = 3.94178e-05
I0321 22:59:12.217223  6540 solver.cpp:228] Iteration 24700, loss = 0.371798
I0321 22:59:12.217290  6540 solver.cpp:244]     Train net output #0: loss = 0.371798 (* 1 = 0.371798 loss)
I0321 22:59:12.217298  6540 sgd_solver.cpp:106] Iteration 24700, lr = 3.93326e-05
I0321 22:59:44.456902  6540 solver.cpp:228] Iteration 24800, loss = 0.372908
I0321 22:59:44.457226  6540 solver.cpp:244]     Train net output #0: loss = 0.372908 (* 1 = 0.372908 loss)
I0321 22:59:44.457233  6540 sgd_solver.cpp:106] Iteration 24800, lr = 3.92478e-05
I0321 23:00:16.730327  6540 solver.cpp:228] Iteration 24900, loss = 0.352145
I0321 23:00:16.730420  6540 solver.cpp:244]     Train net output #0: loss = 0.352145 (* 1 = 0.352145 loss)
I0321 23:00:16.730428  6540 sgd_solver.cpp:106] Iteration 24900, lr = 3.91634e-05
I0321 23:00:48.731019  6540 solver.cpp:454] Snapshotting to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_25000.caffemodel
I0321 23:00:48.928566  6540 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_25000.solverstate
I0321 23:00:48.930351  6540 solver.cpp:337] Iteration 25000, Testing net (#0)
I0321 23:00:49.398975  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88246
I0321 23:00:49.399013  6540 solver.cpp:404]     Test net output #1: loss = 0.384142 (* 1 = 0.384142 loss)
I0321 23:00:49.530854  6540 solver.cpp:228] Iteration 25000, loss = 0.368109
I0321 23:00:49.530881  6540 solver.cpp:244]     Train net output #0: loss = 0.368109 (* 1 = 0.368109 loss)
I0321 23:00:49.530887  6540 sgd_solver.cpp:106] Iteration 25000, lr = 3.90795e-05
I0321 23:01:21.798926  6540 solver.cpp:228] Iteration 25100, loss = 0.37363
I0321 23:01:21.799024  6540 solver.cpp:244]     Train net output #0: loss = 0.37363 (* 1 = 0.37363 loss)
I0321 23:01:21.799032  6540 sgd_solver.cpp:106] Iteration 25100, lr = 3.8996e-05
I0321 23:01:53.992147  6540 solver.cpp:228] Iteration 25200, loss = 0.372785
I0321 23:01:53.992245  6540 solver.cpp:244]     Train net output #0: loss = 0.372785 (* 1 = 0.372785 loss)
I0321 23:01:53.992254  6540 sgd_solver.cpp:106] Iteration 25200, lr = 3.89128e-05
I0321 23:02:26.241035  6540 solver.cpp:228] Iteration 25300, loss = 0.351209
I0321 23:02:26.241144  6540 solver.cpp:244]     Train net output #0: loss = 0.351209 (* 1 = 0.351209 loss)
I0321 23:02:26.241161  6540 sgd_solver.cpp:106] Iteration 25300, lr = 3.88301e-05
I0321 23:02:58.545512  6540 solver.cpp:228] Iteration 25400, loss = 0.365395
I0321 23:02:58.545601  6540 solver.cpp:244]     Train net output #0: loss = 0.365395 (* 1 = 0.365395 loss)
I0321 23:02:58.545619  6540 sgd_solver.cpp:106] Iteration 25400, lr = 3.87478e-05
I0321 23:03:30.443650  6540 solver.cpp:337] Iteration 25500, Testing net (#0)
I0321 23:03:31.105049  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88234
I0321 23:03:31.105075  6540 solver.cpp:404]     Test net output #1: loss = 0.383329 (* 1 = 0.383329 loss)
I0321 23:03:31.238229  6540 solver.cpp:228] Iteration 25500, loss = 0.370446
I0321 23:03:31.238265  6540 solver.cpp:244]     Train net output #0: loss = 0.370446 (* 1 = 0.370446 loss)
I0321 23:03:31.238272  6540 sgd_solver.cpp:106] Iteration 25500, lr = 3.8666e-05
I0321 23:04:03.478216  6540 solver.cpp:228] Iteration 25600, loss = 0.372361
I0321 23:04:03.478313  6540 solver.cpp:244]     Train net output #0: loss = 0.372361 (* 1 = 0.372361 loss)
I0321 23:04:03.478322  6540 sgd_solver.cpp:106] Iteration 25600, lr = 3.85845e-05
I0321 23:04:35.765631  6540 solver.cpp:228] Iteration 25700, loss = 0.350866
I0321 23:04:35.765720  6540 solver.cpp:244]     Train net output #0: loss = 0.350866 (* 1 = 0.350866 loss)
I0321 23:04:35.765738  6540 sgd_solver.cpp:106] Iteration 25700, lr = 3.85034e-05
I0321 23:05:08.017693  6540 solver.cpp:228] Iteration 25800, loss = 0.362676
I0321 23:05:08.017803  6540 solver.cpp:244]     Train net output #0: loss = 0.362676 (* 1 = 0.362676 loss)
I0321 23:05:08.017810  6540 sgd_solver.cpp:106] Iteration 25800, lr = 3.84227e-05
I0321 23:05:40.325876  6540 solver.cpp:228] Iteration 25900, loss = 0.368825
I0321 23:05:40.325956  6540 solver.cpp:244]     Train net output #0: loss = 0.368825 (* 1 = 0.368825 loss)
I0321 23:05:40.325973  6540 sgd_solver.cpp:106] Iteration 25900, lr = 3.83424e-05
I0321 23:06:12.257089  6540 solver.cpp:337] Iteration 26000, Testing net (#0)
I0321 23:06:12.923046  6540 solver.cpp:404]     Test net output #0: accuracy = 0.883
I0321 23:06:12.923080  6540 solver.cpp:404]     Test net output #1: loss = 0.381759 (* 1 = 0.381759 loss)
I0321 23:06:13.056156  6540 solver.cpp:228] Iteration 26000, loss = 0.370257
I0321 23:06:13.056192  6540 solver.cpp:244]     Train net output #0: loss = 0.370257 (* 1 = 0.370257 loss)
I0321 23:06:13.056200  6540 sgd_solver.cpp:106] Iteration 26000, lr = 3.82625e-05
I0321 23:06:45.292441  6540 solver.cpp:228] Iteration 26100, loss = 0.350457
I0321 23:06:45.292541  6540 solver.cpp:244]     Train net output #0: loss = 0.350457 (* 1 = 0.350457 loss)
I0321 23:06:45.292548  6540 sgd_solver.cpp:106] Iteration 26100, lr = 3.8183e-05
I0321 23:07:17.560744  6540 solver.cpp:228] Iteration 26200, loss = 0.361373
I0321 23:07:17.560845  6540 solver.cpp:244]     Train net output #0: loss = 0.361373 (* 1 = 0.361373 loss)
I0321 23:07:17.560853  6540 sgd_solver.cpp:106] Iteration 26200, lr = 3.81038e-05
I0321 23:07:49.880350  6540 solver.cpp:228] Iteration 26300, loss = 0.3688
I0321 23:07:49.880525  6540 solver.cpp:244]     Train net output #0: loss = 0.3688 (* 1 = 0.3688 loss)
I0321 23:07:49.880533  6540 sgd_solver.cpp:106] Iteration 26300, lr = 3.80251e-05
I0321 23:08:22.081909  6540 solver.cpp:228] Iteration 26400, loss = 0.368805
I0321 23:08:22.081965  6540 solver.cpp:244]     Train net output #0: loss = 0.368805 (* 1 = 0.368805 loss)
I0321 23:08:22.081972  6540 sgd_solver.cpp:106] Iteration 26400, lr = 3.79467e-05
I0321 23:08:54.341979  6540 solver.cpp:337] Iteration 26500, Testing net (#0)
I0321 23:08:55.035260  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88332
I0321 23:08:55.035284  6540 solver.cpp:404]     Test net output #1: loss = 0.380362 (* 1 = 0.380362 loss)
I0321 23:08:55.176383  6540 solver.cpp:228] Iteration 26500, loss = 0.350145
I0321 23:08:55.176417  6540 solver.cpp:244]     Train net output #0: loss = 0.350145 (* 1 = 0.350145 loss)
I0321 23:08:55.176425  6540 sgd_solver.cpp:106] Iteration 26500, lr = 3.78687e-05
I0321 23:09:27.457939  6540 solver.cpp:228] Iteration 26600, loss = 0.35834
I0321 23:09:27.458020  6540 solver.cpp:244]     Train net output #0: loss = 0.35834 (* 1 = 0.35834 loss)
I0321 23:09:27.458037  6540 sgd_solver.cpp:106] Iteration 26600, lr = 3.77911e-05
I0321 23:09:59.661218  6540 solver.cpp:228] Iteration 26700, loss = 0.368683
I0321 23:09:59.661301  6540 solver.cpp:244]     Train net output #0: loss = 0.368683 (* 1 = 0.368683 loss)
I0321 23:09:59.661319  6540 sgd_solver.cpp:106] Iteration 26700, lr = 3.77138e-05
I0321 23:10:31.893868  6540 solver.cpp:228] Iteration 26800, loss = 0.368885
I0321 23:10:31.893949  6540 solver.cpp:244]     Train net output #0: loss = 0.368885 (* 1 = 0.368885 loss)
I0321 23:10:31.893965  6540 sgd_solver.cpp:106] Iteration 26800, lr = 3.76369e-05
I0321 23:11:04.019174  6540 solver.cpp:228] Iteration 26900, loss = 0.347696
I0321 23:11:04.019250  6540 solver.cpp:244]     Train net output #0: loss = 0.347696 (* 1 = 0.347696 loss)
I0321 23:11:04.019258  6540 sgd_solver.cpp:106] Iteration 26900, lr = 3.75604e-05
I0321 23:11:35.812196  6540 solver.cpp:337] Iteration 27000, Testing net (#0)
I0321 23:11:36.474222  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88366
I0321 23:11:36.474251  6540 solver.cpp:404]     Test net output #1: loss = 0.379266 (* 1 = 0.379266 loss)
I0321 23:11:36.605562  6540 solver.cpp:228] Iteration 27000, loss = 0.35653
I0321 23:11:36.605600  6540 solver.cpp:244]     Train net output #0: loss = 0.35653 (* 1 = 0.35653 loss)
I0321 23:11:36.605607  6540 sgd_solver.cpp:106] Iteration 27000, lr = 3.74842e-05
I0321 23:12:08.737834  6540 solver.cpp:228] Iteration 27100, loss = 0.366079
I0321 23:12:08.737931  6540 solver.cpp:244]     Train net output #0: loss = 0.366079 (* 1 = 0.366079 loss)
I0321 23:12:08.737939  6540 sgd_solver.cpp:106] Iteration 27100, lr = 3.74084e-05
I0321 23:12:40.868142  6540 solver.cpp:228] Iteration 27200, loss = 0.366446
I0321 23:12:40.868212  6540 solver.cpp:244]     Train net output #0: loss = 0.366446 (* 1 = 0.366446 loss)
I0321 23:12:40.868229  6540 sgd_solver.cpp:106] Iteration 27200, lr = 3.7333e-05
I0321 23:13:13.003370  6540 solver.cpp:228] Iteration 27300, loss = 0.348043
I0321 23:13:13.003440  6540 solver.cpp:244]     Train net output #0: loss = 0.348043 (* 1 = 0.348043 loss)
I0321 23:13:13.003448  6540 sgd_solver.cpp:106] Iteration 27300, lr = 3.72579e-05
I0321 23:13:45.032845  6540 solver.cpp:228] Iteration 27400, loss = 0.357232
I0321 23:13:45.032923  6540 solver.cpp:244]     Train net output #0: loss = 0.357232 (* 1 = 0.357232 loss)
I0321 23:13:45.032940  6540 sgd_solver.cpp:106] Iteration 27400, lr = 3.71832e-05
I0321 23:14:16.788455  6540 solver.cpp:337] Iteration 27500, Testing net (#0)
I0321 23:14:17.447202  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88402
I0321 23:14:17.447227  6540 solver.cpp:404]     Test net output #1: loss = 0.378337 (* 1 = 0.378337 loss)
I0321 23:14:17.580327  6540 solver.cpp:228] Iteration 27500, loss = 0.365633
I0321 23:14:17.580363  6540 solver.cpp:244]     Train net output #0: loss = 0.365633 (* 1 = 0.365633 loss)
I0321 23:14:17.580370  6540 sgd_solver.cpp:106] Iteration 27500, lr = 3.71088e-05
I0321 23:14:49.642892  6540 solver.cpp:228] Iteration 27600, loss = 0.364142
I0321 23:14:49.642989  6540 solver.cpp:244]     Train net output #0: loss = 0.364142 (* 1 = 0.364142 loss)
I0321 23:14:49.642997  6540 sgd_solver.cpp:106] Iteration 27600, lr = 3.70347e-05
I0321 23:15:21.527173  6540 solver.cpp:228] Iteration 27700, loss = 0.344829
I0321 23:15:21.527251  6540 solver.cpp:244]     Train net output #0: loss = 0.344829 (* 1 = 0.344829 loss)
I0321 23:15:21.527266  6540 sgd_solver.cpp:106] Iteration 27700, lr = 3.6961e-05
I0321 23:15:53.305661  6540 solver.cpp:228] Iteration 27800, loss = 0.355836
I0321 23:15:53.305722  6540 solver.cpp:244]     Train net output #0: loss = 0.355836 (* 1 = 0.355836 loss)
I0321 23:15:53.305730  6540 sgd_solver.cpp:106] Iteration 27800, lr = 3.68877e-05
I0321 23:16:25.126909  6540 solver.cpp:228] Iteration 27900, loss = 0.36351
I0321 23:16:25.126976  6540 solver.cpp:244]     Train net output #0: loss = 0.36351 (* 1 = 0.36351 loss)
I0321 23:16:25.126982  6540 sgd_solver.cpp:106] Iteration 27900, lr = 3.68146e-05
I0321 23:16:56.634832  6540 solver.cpp:337] Iteration 28000, Testing net (#0)
I0321 23:16:57.313462  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88434
I0321 23:16:57.313498  6540 solver.cpp:404]     Test net output #1: loss = 0.377463 (* 1 = 0.377463 loss)
I0321 23:16:57.446085  6540 solver.cpp:228] Iteration 28000, loss = 0.362197
I0321 23:16:57.446120  6540 solver.cpp:244]     Train net output #0: loss = 0.362197 (* 1 = 0.362197 loss)
I0321 23:16:57.446127  6540 sgd_solver.cpp:106] Iteration 28000, lr = 3.6742e-05
I0321 23:17:29.544304  6540 solver.cpp:228] Iteration 28100, loss = 0.343769
I0321 23:17:29.544404  6540 solver.cpp:244]     Train net output #0: loss = 0.343769 (* 1 = 0.343769 loss)
I0321 23:17:29.544411  6540 sgd_solver.cpp:106] Iteration 28100, lr = 3.66696e-05
I0321 23:18:01.633412  6540 solver.cpp:228] Iteration 28200, loss = 0.354885
I0321 23:18:01.633492  6540 solver.cpp:244]     Train net output #0: loss = 0.354885 (* 1 = 0.354885 loss)
I0321 23:18:01.633508  6540 sgd_solver.cpp:106] Iteration 28200, lr = 3.65976e-05
I0321 23:18:33.691092  6540 solver.cpp:228] Iteration 28300, loss = 0.362165
I0321 23:18:33.691189  6540 solver.cpp:244]     Train net output #0: loss = 0.362165 (* 1 = 0.362165 loss)
I0321 23:18:33.691196  6540 sgd_solver.cpp:106] Iteration 28300, lr = 3.65259e-05
I0321 23:19:05.799167  6540 solver.cpp:228] Iteration 28400, loss = 0.362228
I0321 23:19:05.799237  6540 solver.cpp:244]     Train net output #0: loss = 0.362228 (* 1 = 0.362228 loss)
I0321 23:19:05.799244  6540 sgd_solver.cpp:106] Iteration 28400, lr = 3.64545e-05
I0321 23:19:37.529610  6540 solver.cpp:337] Iteration 28500, Testing net (#0)
I0321 23:19:38.191753  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88448
I0321 23:19:38.191779  6540 solver.cpp:404]     Test net output #1: loss = 0.3764 (* 1 = 0.3764 loss)
I0321 23:19:38.324748  6540 solver.cpp:228] Iteration 28500, loss = 0.345518
I0321 23:19:38.324784  6540 solver.cpp:244]     Train net output #0: loss = 0.345518 (* 1 = 0.345518 loss)
I0321 23:19:38.324790  6540 sgd_solver.cpp:106] Iteration 28500, lr = 3.63835e-05
I0321 23:20:10.366626  6540 solver.cpp:228] Iteration 28600, loss = 0.354726
I0321 23:20:10.366693  6540 solver.cpp:244]     Train net output #0: loss = 0.354726 (* 1 = 0.354726 loss)
I0321 23:20:10.366701  6540 sgd_solver.cpp:106] Iteration 28600, lr = 3.63128e-05
I0321 23:20:42.407699  6540 solver.cpp:228] Iteration 28700, loss = 0.36121
I0321 23:20:42.407780  6540 solver.cpp:244]     Train net output #0: loss = 0.36121 (* 1 = 0.36121 loss)
I0321 23:20:42.407797  6540 sgd_solver.cpp:106] Iteration 28700, lr = 3.62424e-05
I0321 23:21:14.431839  6540 solver.cpp:228] Iteration 28800, loss = 0.362131
I0321 23:21:14.431910  6540 solver.cpp:244]     Train net output #0: loss = 0.362131 (* 1 = 0.362131 loss)
I0321 23:21:14.431917  6540 sgd_solver.cpp:106] Iteration 28800, lr = 3.61723e-05
I0321 23:21:46.509054  6540 solver.cpp:228] Iteration 28900, loss = 0.343057
I0321 23:21:46.509124  6540 solver.cpp:244]     Train net output #0: loss = 0.343057 (* 1 = 0.343057 loss)
I0321 23:21:46.509130  6540 sgd_solver.cpp:106] Iteration 28900, lr = 3.61025e-05
I0321 23:22:18.233050  6540 solver.cpp:337] Iteration 29000, Testing net (#0)
I0321 23:22:18.890043  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88522
I0321 23:22:18.890079  6540 solver.cpp:404]     Test net output #1: loss = 0.374676 (* 1 = 0.374676 loss)
I0321 23:22:19.023064  6540 solver.cpp:228] Iteration 29000, loss = 0.352358
I0321 23:22:19.023100  6540 solver.cpp:244]     Train net output #0: loss = 0.352358 (* 1 = 0.352358 loss)
I0321 23:22:19.023108  6540 sgd_solver.cpp:106] Iteration 29000, lr = 3.60331e-05
I0321 23:22:51.032551  6540 solver.cpp:228] Iteration 29100, loss = 0.360762
I0321 23:22:51.032642  6540 solver.cpp:244]     Train net output #0: loss = 0.360762 (* 1 = 0.360762 loss)
I0321 23:22:51.032650  6540 sgd_solver.cpp:106] Iteration 29100, lr = 3.5964e-05
I0321 23:23:23.025645  6540 solver.cpp:228] Iteration 29200, loss = 0.362895
I0321 23:23:23.025745  6540 solver.cpp:244]     Train net output #0: loss = 0.362895 (* 1 = 0.362895 loss)
I0321 23:23:23.025763  6540 sgd_solver.cpp:106] Iteration 29200, lr = 3.58951e-05
I0321 23:23:55.067838  6540 solver.cpp:228] Iteration 29300, loss = 0.34108
I0321 23:23:55.067919  6540 solver.cpp:244]     Train net output #0: loss = 0.34108 (* 1 = 0.34108 loss)
I0321 23:23:55.067926  6540 sgd_solver.cpp:106] Iteration 29300, lr = 3.58266e-05
I0321 23:24:27.109061  6540 solver.cpp:228] Iteration 29400, loss = 0.351084
I0321 23:24:27.109139  6540 solver.cpp:244]     Train net output #0: loss = 0.351084 (* 1 = 0.351084 loss)
I0321 23:24:27.109156  6540 sgd_solver.cpp:106] Iteration 29400, lr = 3.57584e-05
I0321 23:24:58.877326  6540 solver.cpp:337] Iteration 29500, Testing net (#0)
I0321 23:24:59.538203  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88532
I0321 23:24:59.538242  6540 solver.cpp:404]     Test net output #1: loss = 0.374869 (* 1 = 0.374869 loss)
I0321 23:24:59.671108  6540 solver.cpp:228] Iteration 29500, loss = 0.359464
I0321 23:24:59.671144  6540 solver.cpp:244]     Train net output #0: loss = 0.359464 (* 1 = 0.359464 loss)
I0321 23:24:59.671150  6540 sgd_solver.cpp:106] Iteration 29500, lr = 3.56905e-05
I0321 23:25:31.708017  6540 solver.cpp:228] Iteration 29600, loss = 0.362683
I0321 23:25:31.708118  6540 solver.cpp:244]     Train net output #0: loss = 0.362683 (* 1 = 0.362683 loss)
I0321 23:25:31.708127  6540 sgd_solver.cpp:106] Iteration 29600, lr = 3.56228e-05
I0321 23:26:03.756742  6540 solver.cpp:228] Iteration 29700, loss = 0.340361
I0321 23:26:03.756836  6540 solver.cpp:244]     Train net output #0: loss = 0.340361 (* 1 = 0.340361 loss)
I0321 23:26:03.756844  6540 sgd_solver.cpp:106] Iteration 29700, lr = 3.55555e-05
I0321 23:26:35.784529  6540 solver.cpp:228] Iteration 29800, loss = 0.351326
I0321 23:26:35.784611  6540 solver.cpp:244]     Train net output #0: loss = 0.351326 (* 1 = 0.351326 loss)
I0321 23:26:35.784618  6540 sgd_solver.cpp:106] Iteration 29800, lr = 3.54885e-05
I0321 23:27:07.806748  6540 solver.cpp:228] Iteration 29900, loss = 0.357334
I0321 23:27:07.806849  6540 solver.cpp:244]     Train net output #0: loss = 0.357334 (* 1 = 0.357334 loss)
I0321 23:27:07.806856  6540 sgd_solver.cpp:106] Iteration 29900, lr = 3.54218e-05
I0321 23:27:39.508949  6540 solver.cpp:454] Snapshotting to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_30000.caffemodel
I0321 23:27:39.707309  6540 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/nikoong/Algorithm_test/handwritting/lenet/snapshots/ft_mnist_balance_lmdb_iter_30000.solverstate
I0321 23:27:39.849381  6540 solver.cpp:317] Iteration 30000, loss = 0.360502
I0321 23:27:39.849405  6540 solver.cpp:337] Iteration 30000, Testing net (#0)
I0321 23:27:40.340483  6540 solver.cpp:404]     Test net output #0: accuracy = 0.88566
I0321 23:27:40.340520  6540 solver.cpp:404]     Test net output #1: loss = 0.373229 (* 1 = 0.373229 loss)
I0321 23:27:40.340528  6540 solver.cpp:322] Optimization Done.
I0321 23:27:40.340530  6540 caffe.cpp:223] Optimization Done.
